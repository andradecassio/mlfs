{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "899e0774",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39228e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import weka.core.jvm as jvm\n",
    "import weka.core.converters as converters\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from scipy.io import arff\n",
    "from scipy.stats import t\n",
    "import weka.core.jvm as jvm\n",
    "from weka.attribute_selection import ASSearch\n",
    "from weka.attribute_selection import ASEvaluation\n",
    "from weka.attribute_selection import AttributeSelection\n",
    "import weka.core.converters as converters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from scipy.io import arff\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "172f2da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:weka.core.jvm:Adding bundled jars\n",
      "DEBUG:weka.core.jvm:Classpath=['C:\\\\Users\\\\Cassio\\\\.conda\\\\envs\\\\pww3\\\\Lib\\\\site-packages\\\\javabridge\\\\jars\\\\rhino-1.7R4.jar', 'C:\\\\Users\\\\Cassio\\\\.conda\\\\envs\\\\pww3\\\\Lib\\\\site-packages\\\\javabridge\\\\jars\\\\runnablequeue.jar', 'C:\\\\Users\\\\Cassio\\\\.conda\\\\envs\\\\pww3\\\\Lib\\\\site-packages\\\\javabridge\\\\jars\\\\cpython.jar', 'c:\\\\Users\\\\Cassio\\\\.conda\\\\envs\\\\pww3\\\\lib\\\\site-packages\\\\weka\\\\lib\\\\python-weka-wrapper.jar', 'c:\\\\Users\\\\Cassio\\\\.conda\\\\envs\\\\pww3\\\\lib\\\\site-packages\\\\weka\\\\lib\\\\weka.jar']\n",
      "DEBUG:weka.core.jvm:MaxHeapSize=default\n",
      "DEBUG:weka.core.jvm:Package support enabled\n"
     ]
    }
   ],
   "source": [
    "jvm.start(packages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da4c5d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if some WEKA package is not installed:\n",
    "# package_name = \"chiSquaredAttributeEval\"\n",
    "# package_installed = False\n",
    "# for p in pkg.installed_packages():\n",
    "#     if p.name == package_name:\n",
    "#         package_installed = True\n",
    "#         print(\"pkg %s already installed\" % package_name)\n",
    "# if not package_installed:\n",
    "#     pkg.install_package(package_name)\n",
    "#     print(\"pkg %s installed, please restart\" % package_name)\n",
    "#     jvm.stop()\n",
    "#     sys.exit(1)\n",
    "#     jvm.start(packages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c746bd0a",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28a276b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving to project directory \n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afaf6083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Cassio\\\\Desktop\\\\MLFS_git\\\\ml_fs'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if current directory is mlfs\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a9c68a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseClassifier</th>\n",
       "      <th>datasetName</th>\n",
       "      <th>attributeName</th>\n",
       "      <th>wrapperRelevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>iris</td>\n",
       "      <td>petallength</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>iris</td>\n",
       "      <td>petalwidth</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>iris</td>\n",
       "      <td>sepallength</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>iris</td>\n",
       "      <td>sepalwidth</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>labor_part1</td>\n",
       "      <td>wage-increase-second-year</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>zoo</td>\n",
       "      <td>aquatic</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>zoo</td>\n",
       "      <td>catsize</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>zoo</td>\n",
       "      <td>venomous</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>zoo</td>\n",
       "      <td>predator</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>zoo</td>\n",
       "      <td>domestic</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               baseClassifier  datasetName              attributeName  \\\n",
       "0    simpleLogisticRegression         iris                petallength   \n",
       "1    simpleLogisticRegression         iris                 petalwidth   \n",
       "2    simpleLogisticRegression         iris                sepallength   \n",
       "3    simpleLogisticRegression         iris                 sepalwidth   \n",
       "4    simpleLogisticRegression  labor_part1  wage-increase-second-year   \n",
       "..                        ...          ...                        ...   \n",
       "488  simpleLogisticRegression          zoo                    aquatic   \n",
       "489  simpleLogisticRegression          zoo                    catsize   \n",
       "490  simpleLogisticRegression          zoo                   venomous   \n",
       "491  simpleLogisticRegression          zoo                   predator   \n",
       "492  simpleLogisticRegression          zoo                   domestic   \n",
       "\n",
       "    wrapperRelevance  \n",
       "0                 no  \n",
       "1                yes  \n",
       "2                 no  \n",
       "3                 no  \n",
       "4                yes  \n",
       "..               ...  \n",
       "488              yes  \n",
       "489               no  \n",
       "490               no  \n",
       "491               no  \n",
       "492               no  \n",
       "\n",
       "[493 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = pd.read_csv('data\\\\processed\\\\wrapper_data_set.csv')\n",
    "data_set['datasetName'] = data_set['datasetName'].str.replace(\"-\", \"_\")\n",
    "data_set['attributeName'] = data_set['attributeName'].str.replace(\" \", \"_\")\n",
    "data_set = data_set[['baseClassifier','datasetName','attributeName','wrapperRelevance']]\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4580e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasetName\n",
    "groups = data_set.iloc[:,:].datasetName"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c3c80a",
   "metadata": {},
   "source": [
    "# Importing arff files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a39452",
   "metadata": {},
   "source": [
    "## Storing arfffiles as dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945e8f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: abalone_classification\n",
      "Number of instances: 4177\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 7\n",
      "Number of categorical attributes: 1\n",
      "Number of classes: 28\n",
      "\n",
      "Dataset: accent_mfcc_data_1\n",
      "Number of instances: 329\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 12\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: avila_tr\n",
      "Number of instances: 10430\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 10\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 12\n",
      "\n",
      "Dataset: avila_ts\n",
      "Number of instances: 10437\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 10\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 12\n",
      "\n",
      "Dataset: balance_scale\n",
      "Number of instances: 625\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 0\n",
      "Number of categorical attributes: 4\n",
      "Number of classes: 3\n",
      "\n",
      "Dataset: breast_cancer\n",
      "Number of instances: 286\n",
      "Missing values: 0.34965034965034963 %\n",
      "Number of numeric attributes: 0\n",
      "Number of categorical attributes: 9\n",
      "Number of classes: 2\n",
      "\n",
      "Dataset: cmc\n",
      "Number of instances: 1473\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 2\n",
      "Number of categorical attributes: 7\n",
      "Number of classes: 3\n",
      "\n",
      "Dataset: contact_lenses\n",
      "Number of instances: 24\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 0\n",
      "Number of categorical attributes: 4\n",
      "Number of classes: 3\n",
      "\n",
      "Dataset: credit_g\n",
      "Number of instances: 1000\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 7\n",
      "Number of categorical attributes: 13\n",
      "Number of classes: 2\n",
      "\n",
      "Dataset: data_banknote_authentication\n",
      "Number of instances: 1372\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 4\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 2\n",
      "\n",
      "Dataset: diabetes\n",
      "Number of instances: 768\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 8\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 2\n",
      "\n",
      "Dataset: DishonestInternetUsers\n",
      "Number of instances: 322\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 0\n",
      "Number of categorical attributes: 4\n",
      "Number of classes: 2\n",
      "\n",
      "Dataset: ecoli\n",
      "Number of instances: 336\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 7\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 8\n",
      "\n",
      "Dataset: EEG_Eye_State\n",
      "Number of instances: 14980\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 14\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 2\n",
      "\n",
      "Dataset: glass\n",
      "Number of instances: 214\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 9\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 6\n",
      "\n",
      "Dataset: hayes_roth_trainAndtest\n",
      "Number of instances: 160\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 0\n",
      "Number of categorical attributes: 4\n",
      "Number of classes: 3\n",
      "\n",
      "Dataset: hcvdat0\n",
      "Number of instances: 615\n",
      "Missing values: 0.4200542005420054 %\n",
      "Number of numeric attributes: 11\n",
      "Number of categorical attributes: 1\n",
      "Number of classes: 5\n",
      "\n",
      "Dataset: hypothyroid\n",
      "Number of instances: 3772\n",
      "Missing values: 5.543569678575346 %\n",
      "Number of numeric attributes: 7\n",
      "Number of categorical attributes: 22\n",
      "Number of classes: 4\n",
      "\n",
      "Dataset: ionosphere\n",
      "Number of instances: 351\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 34\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 2\n",
      "\n",
      "Dataset: iris\n",
      "Number of instances: 150\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 4\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 3\n",
      "\n",
      "Dataset: labor\n",
      "Number of instances: 57\n",
      "Missing values: 35.74561403508772 %\n",
      "Number of numeric attributes: 8\n",
      "Number of categorical attributes: 8\n",
      "Number of classes: 2\n",
      "\n",
      "Dataset: magic04\n",
      "Number of instances: 19020\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 10\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 2\n",
      "\n",
      "Dataset: mammographic_masses\n",
      "Number of instances: 961\n",
      "Missing values: 3.3714880332986477 %\n",
      "Number of numeric attributes: 3\n",
      "Number of categorical attributes: 2\n",
      "Number of classes: 2\n",
      "\n",
      "Dataset: monks_1_train\n",
      "Number of instances: 124\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 0\n",
      "Number of categorical attributes: 6\n",
      "Number of classes: 2\n",
      "\n",
      "Dataset: monks_2_train\n",
      "Number of instances: 169\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 0\n",
      "Number of categorical attributes: 6\n",
      "Number of classes: 2\n",
      "\n",
      "Dataset: ObesityDataSet_raw_and_data_sinthetic\n",
      "Number of instances: 2111\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 8\n",
      "Number of categorical attributes: 8\n",
      "Number of classes: 7\n",
      "\n",
      "Dataset: seeds_dataset\n",
      "Number of instances: 210\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 7\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 3\n",
      "\n",
      "Dataset: segment_challenge\n",
      "Number of instances: 1500\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 19\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 7\n",
      "\n",
      "Dataset: sonar_all_data\n",
      "Number of instances: 208\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 60\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 2\n",
      "\n",
      "Dataset: soybean\n",
      "Number of instances: 683\n",
      "Missing values: 9.776197448232587 %\n",
      "Number of numeric attributes: 0\n",
      "Number of categorical attributes: 35\n",
      "Number of classes: 19\n",
      "\n",
      "Dataset: Surveillance\n",
      "Number of instances: 14\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 0\n",
      "Number of categorical attributes: 7\n",
      "Number of classes: 3\n",
      "\n",
      "Dataset: vote\n",
      "Number of instances: 435\n",
      "Missing values: 5.632183908045977 %\n",
      "Number of numeric attributes: 0\n",
      "Number of categorical attributes: 16\n",
      "Number of classes: 2\n",
      "\n",
      "Dataset: weather_nominal\n",
      "Number of instances: 14\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 0\n",
      "Number of categorical attributes: 4\n",
      "Number of classes: 2\n",
      "\n",
      "Dataset: wifi_localization\n",
      "Number of instances: 2000\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 7\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 4\n",
      "\n",
      "Dataset: wilt\n",
      "Number of instances: 4839\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 5\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 2\n",
      "\n",
      "Dataset: wine\n",
      "Number of instances: 178\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 13\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 3\n",
      "\n",
      "Dataset: winequality_red_classification\n",
      "Number of instances: 1599\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 11\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 6\n",
      "\n",
      "Dataset: winequality_white_classification\n",
      "Number of instances: 4898\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 11\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 7\n",
      "\n",
      "Dataset: yeast\n",
      "Number of instances: 1484\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 8\n",
      "Number of categorical attributes: 0\n",
      "Number of classes: 10\n",
      "\n",
      "Dataset: zoo\n",
      "Number of instances: 101\n",
      "Missing values: 0.0 %\n",
      "Number of numeric attributes: 1\n",
      "Number of categorical attributes: 15\n",
      "Number of classes: 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reading arff files and storing in dataframes\n",
    "\n",
    "path = os.getcwd()+'\\\\data\\\\raw'\n",
    "arff_files = glob.glob(os.path.join(path, \"*.arff\"))\n",
    "arff_files = ([s for s in arff_files if 'part' not in s])\n",
    "\n",
    "col1 =[]\n",
    "col2=[]\n",
    "col3=[]\n",
    "col4=[]\n",
    "col5 =[]\n",
    "col6=[]\n",
    "\n",
    "\n",
    "for f in arff_files:\n",
    "      \n",
    "    data = arff.loadarff(f)\n",
    "    nome = f.split(\"\\\\\")[-1]\n",
    "    nome = nome.replace(\".arff\", \"\")\n",
    "    nome = nome.replace(\"-\", \"_\")\n",
    "    d =  pd.DataFrame(data[0]) # auxiliar df\n",
    "    categorical_columns_selector = selector(dtype_include=object)   #treating categorical columns from arff extension\n",
    "    categorical_columns = categorical_columns_selector(d)\n",
    "    d[categorical_columns] = d[categorical_columns].stack().str.decode('utf-8').unstack()\n",
    "    d = d.replace('?',np.NaN)\n",
    "    d.columns = d.columns.str.replace(' ', '_')\n",
    "    \n",
    "    print('Dataset:',nome)\n",
    "    print('Number of instances:',len(d))\n",
    "    print('Missing values:',(d.isnull().sum().sum() / (len(d)*(len(d.columns)-1)))*100,'%')    \n",
    "    print('Number of numeric attributes:',len(d.columns)-1 - (len(categorical_columns)-1))    \n",
    "    print('Number of categorical attributes:',len(categorical_columns)-1)\n",
    "    print('Number of classes:',len(d.iloc[:,-1].unique()))\n",
    "    print('')\n",
    "    \n",
    "    col1.append(nome)\n",
    "    col2.append(len(d))\n",
    "    col3.append((d.isnull().sum().sum() / (len(d)*(len(d.columns)-1)))*100)\n",
    "    col4.append(len(d.columns)-1 - (len(categorical_columns)-1))\n",
    "    col5.append(len(categorical_columns)-1)\n",
    "    col6.append(len(d.iloc[:,-1].unique()))\n",
    "\n",
    "    exec('dataset_{KEY} = d.copy()'.format(KEY = nome))\n",
    "    \n",
    "table1 = pd.DataFrame(\n",
    " {'Dataset': col1,\n",
    "  'Instances': col2,\n",
    "  'Missing values %': col3,\n",
    "  'Numeric attributes': col4,\n",
    "  'Categorical attributess': col5,\n",
    "  'Classes': col6,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca3486f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Instances</th>\n",
       "      <th>Missing values %</th>\n",
       "      <th>Numeric attributes</th>\n",
       "      <th>Categorical attributess</th>\n",
       "      <th>Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone_classification</td>\n",
       "      <td>4177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accent_mfcc_data_1</td>\n",
       "      <td>329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avila_tr</td>\n",
       "      <td>10430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avila_ts</td>\n",
       "      <td>10437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>balance_scale</td>\n",
       "      <td>625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>286</td>\n",
       "      <td>0.349650</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cmc</td>\n",
       "      <td>1473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>contact_lenses</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>credit_g</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data_banknote_authentication</td>\n",
       "      <td>1372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DishonestInternetUsers</td>\n",
       "      <td>322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ecoli</td>\n",
       "      <td>336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EEG_Eye_State</td>\n",
       "      <td>14980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>glass</td>\n",
       "      <td>214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hayes_roth_trainAndtest</td>\n",
       "      <td>160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hcvdat0</td>\n",
       "      <td>615</td>\n",
       "      <td>0.420054</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hypothyroid</td>\n",
       "      <td>3772</td>\n",
       "      <td>5.543570</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ionosphere</td>\n",
       "      <td>351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>iris</td>\n",
       "      <td>150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>labor</td>\n",
       "      <td>57</td>\n",
       "      <td>35.745614</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>magic04</td>\n",
       "      <td>19020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mammographic_masses</td>\n",
       "      <td>961</td>\n",
       "      <td>3.371488</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>monks_1_train</td>\n",
       "      <td>124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>monks_2_train</td>\n",
       "      <td>169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ObesityDataSet_raw_and_data_sinthetic</td>\n",
       "      <td>2111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>seeds_dataset</td>\n",
       "      <td>210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>segment_challenge</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sonar_all_data</td>\n",
       "      <td>208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>soybean</td>\n",
       "      <td>683</td>\n",
       "      <td>9.776197</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Surveillance</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>vote</td>\n",
       "      <td>435</td>\n",
       "      <td>5.632184</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>weather_nominal</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>wifi_localization</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>wilt</td>\n",
       "      <td>4839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>wine</td>\n",
       "      <td>178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>winequality_red_classification</td>\n",
       "      <td>1599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>winequality_white_classification</td>\n",
       "      <td>4898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>yeast</td>\n",
       "      <td>1484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>zoo</td>\n",
       "      <td>101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Dataset  Instances  Missing values %  \\\n",
       "0                  abalone_classification       4177          0.000000   \n",
       "1                      accent_mfcc_data_1        329          0.000000   \n",
       "2                                avila_tr      10430          0.000000   \n",
       "3                                avila_ts      10437          0.000000   \n",
       "4                           balance_scale        625          0.000000   \n",
       "5                           breast_cancer        286          0.349650   \n",
       "6                                     cmc       1473          0.000000   \n",
       "7                          contact_lenses         24          0.000000   \n",
       "8                                credit_g       1000          0.000000   \n",
       "9            data_banknote_authentication       1372          0.000000   \n",
       "10                               diabetes        768          0.000000   \n",
       "11                 DishonestInternetUsers        322          0.000000   \n",
       "12                                  ecoli        336          0.000000   \n",
       "13                          EEG_Eye_State      14980          0.000000   \n",
       "14                                  glass        214          0.000000   \n",
       "15                hayes_roth_trainAndtest        160          0.000000   \n",
       "16                                hcvdat0        615          0.420054   \n",
       "17                            hypothyroid       3772          5.543570   \n",
       "18                             ionosphere        351          0.000000   \n",
       "19                                   iris        150          0.000000   \n",
       "20                                  labor         57         35.745614   \n",
       "21                                magic04      19020          0.000000   \n",
       "22                    mammographic_masses        961          3.371488   \n",
       "23                          monks_1_train        124          0.000000   \n",
       "24                          monks_2_train        169          0.000000   \n",
       "25  ObesityDataSet_raw_and_data_sinthetic       2111          0.000000   \n",
       "26                          seeds_dataset        210          0.000000   \n",
       "27                      segment_challenge       1500          0.000000   \n",
       "28                         sonar_all_data        208          0.000000   \n",
       "29                                soybean        683          9.776197   \n",
       "30                           Surveillance         14          0.000000   \n",
       "31                                   vote        435          5.632184   \n",
       "32                        weather_nominal         14          0.000000   \n",
       "33                      wifi_localization       2000          0.000000   \n",
       "34                                   wilt       4839          0.000000   \n",
       "35                                   wine        178          0.000000   \n",
       "36         winequality_red_classification       1599          0.000000   \n",
       "37       winequality_white_classification       4898          0.000000   \n",
       "38                                  yeast       1484          0.000000   \n",
       "39                                    zoo        101          0.000000   \n",
       "\n",
       "    Numeric attributes  Categorical attributess  Classes  \n",
       "0                    7                        1       28  \n",
       "1                   12                        0        6  \n",
       "2                   10                        0       12  \n",
       "3                   10                        0       12  \n",
       "4                    0                        4        3  \n",
       "5                    0                        9        2  \n",
       "6                    2                        7        3  \n",
       "7                    0                        4        3  \n",
       "8                    7                       13        2  \n",
       "9                    4                        0        2  \n",
       "10                   8                        0        2  \n",
       "11                   0                        4        2  \n",
       "12                   7                        0        8  \n",
       "13                  14                        0        2  \n",
       "14                   9                        0        6  \n",
       "15                   0                        4        3  \n",
       "16                  11                        1        5  \n",
       "17                   7                       22        4  \n",
       "18                  34                        0        2  \n",
       "19                   4                        0        3  \n",
       "20                   8                        8        2  \n",
       "21                  10                        0        2  \n",
       "22                   3                        2        2  \n",
       "23                   0                        6        2  \n",
       "24                   0                        6        2  \n",
       "25                   8                        8        7  \n",
       "26                   7                        0        3  \n",
       "27                  19                        0        7  \n",
       "28                  60                        0        2  \n",
       "29                   0                       35       19  \n",
       "30                   0                        7        3  \n",
       "31                   0                       16        2  \n",
       "32                   0                        4        2  \n",
       "33                   7                        0        4  \n",
       "34                   5                        0        2  \n",
       "35                  13                        0        3  \n",
       "36                  11                        0        6  \n",
       "37                  11                        0        7  \n",
       "38                   8                        0       10  \n",
       "39                   1                       15        7  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0b82a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/saurabhnagrecha/Pandas-to-ARFF/blob/master/pandas2arff.py\n",
    "def pandas2arff(df,filename,wekaname = \"pandasdata\",cleanstringdata=True,cleannan=True):\n",
    "    \"\"\"\n",
    "    converts the pandas dataframe to a weka compatible file\n",
    "    df: dataframe in pandas format\n",
    "    filename: the filename you want the weka compatible file to be in\n",
    "    wekaname: the name you want to give to the weka dataset (this will be visible to you when you open it in Weka)\n",
    "    cleanstringdata: clean up data which may have spaces and replace with \"_\", special characters etc which seem to annoy Weka. \n",
    "                     To suppress this, set this to False\n",
    "    cleannan: replaces all nan values with \"?\" which is Weka's standard for missing values. \n",
    "              To suppress this, set this to False\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    def cleanstring(s):\n",
    "        if s!=\"?\":\n",
    "            return re.sub('[^A-Za-z0-9]+', \"_\", str(s))\n",
    "        else:\n",
    "            return \"?\"\n",
    "            \n",
    "    dfcopy = df #all cleaning operations get done on this copy\n",
    "\n",
    "    \n",
    "    if cleannan!=False:\n",
    "        dfcopy = dfcopy.fillna(-999999999) #this is so that we can swap this out for \"?\"\n",
    "        #this makes sure that certain numerical columns with missing values don't get stuck with \"object\" type\n",
    " \n",
    "    f = open(filename,\"w\")\n",
    "    arffList = []\n",
    "    arffList.append(\"@relation \" + wekaname + \"\\n\")\n",
    "    #look at each column's dtype. If it's an \"object\", make it \"nominal\" under Weka for now (can be changed in source for dates.. etc)\n",
    "    for i in range(df.shape[1]):\n",
    "#         print(df.columns[i])\n",
    "#         print('df',df.dtypes[i])        \n",
    "#         print('dfcopy',dfcopy.dtypes[i])\n",
    "#         if dfcopy.dtypes[i]=='O' or (df.columns[i] in [\"Class\",\"CLASS\",\"class\"]):\n",
    "        if df.dtypes[i]=='O' or (df.columns[i] in [\"Class\",\"CLASS\",\"class\"]):            \n",
    "#             print('Categorical column')\n",
    "            if cleannan!=False:\n",
    "                dfcopy.iloc[:,i] = dfcopy.iloc[:,i].replace(to_replace=-999999999, value=\"?\")\n",
    "            if cleanstringdata!=False:\n",
    "                dfcopy.iloc[:,i] = dfcopy.iloc[:,i].apply(cleanstring)\n",
    "            _uniqueNominalVals = [str(_i) for _i in np.unique(dfcopy.iloc[:,i])]\n",
    "            _uniqueNominalVals = \",\".join(_uniqueNominalVals)\n",
    "            _uniqueNominalVals = _uniqueNominalVals.replace(\"[\",\"\")\n",
    "            _uniqueNominalVals = _uniqueNominalVals.replace(\"]\",\"\")\n",
    "            _uniqueValuesString = \"{\" + _uniqueNominalVals +\"}\" \n",
    "            arffList.append(\"@attribute \" + df.columns[i] + _uniqueValuesString + \"\\n\")\n",
    "        else:\n",
    "#             print('Numerical column')            \n",
    "            arffList.append(\"@attribute \" + df.columns[i] + \" real\\n\") \n",
    "            #even if it is an integer, let's just deal with it as a real number for now\n",
    "    arffList.append(\"@data\\n\")           \n",
    "    for i in range(dfcopy.shape[0]):#instances\n",
    "        _instanceString = \"\"\n",
    "        for j in range(df.shape[1]):#features\n",
    "                if dfcopy.dtypes[j]=='O':\n",
    "                    _instanceString+=\"\\\"\" + str(dfcopy.iloc[i,j]) + \"\\\"\"\n",
    "                else:\n",
    "                    _instanceString+=str(dfcopy.iloc[i,j])\n",
    "                if j!=dfcopy.shape[1]-1:#if it's not the last feature, add a comma\n",
    "                    _instanceString+=\",\"\n",
    "        _instanceString+=\"\\n\"\n",
    "        if cleannan!=False:\n",
    "            _instanceString = _instanceString.replace(\"-999999999.0\",\"?\") #for numeric missing values\n",
    "            _instanceString = _instanceString.replace(\"\\\"?\\\"\",\"?\") #for categorical missing values\n",
    "        arffList.append(_instanceString)\n",
    "    f.writelines(arffList)\n",
    "    f.close()\n",
    "    del dfcopy\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c160b7bc",
   "metadata": {},
   "source": [
    "## Splited datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adc48cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data\\\\interim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8e79d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file labor_part1 already exists.\n",
      "The file labor_part2 already exists.\n",
      "The file credit_g_part1 already exists.\n",
      "The file credit_g_part2 already exists.\n",
      "The file hypothyroid_part1 already exists.\n",
      "The file hypothyroid_part2 already exists.\n",
      "The file hypothyroid_part3 already exists.\n",
      "The file segment_challenge_part1 already exists.\n",
      "The file segment_challenge_part2 already exists.\n",
      "The file soybean_part1 already exists.\n",
      "The file soybean_part2 already exists.\n",
      "The file soybean_part3 already exists.\n",
      "The file vote_part1 already exists.\n",
      "The file vote_part2 already exists.\n",
      "The file ionosphere_part1 already exists.\n",
      "The file ionosphere_part2 already exists.\n",
      "The file ionosphere_part3 already exists.\n",
      "The file sonar_all_data_part1 already exists.\n",
      "The file sonar_all_data_part2 already exists.\n",
      "The file sonar_all_data_part3 already exists.\n",
      "The file sonar_all_data_part4 already exists.\n",
      "The file sonar_all_data_part5 already exists.\n"
     ]
    }
   ],
   "source": [
    "# criando dataframes que foram particionados a partir dos dataframes completos\n",
    "col_part = list(groups.unique()[pd.Series(groups.unique()).str.contains(\"part\")])\n",
    "variaveis = data_set.iloc[:,1:3].groupby('datasetName')['attributeName'].apply(lambda x: x.tolist()).to_dict()\n",
    "for nome_dataset in col_part:\n",
    "    pai = 'dataset_'+nome_dataset[:-6]\n",
    "    exec('dataset_{KEY} = {KEY2}.loc[:,variaveis[\"{KEY}\"]]'.format(KEY = nome_dataset,KEY2 = pai))\n",
    "    exec('dataset_{KEY} = pd.concat([dataset_{KEY}, {KEY2}.iloc[:,-1]], axis=1)'.format(KEY = nome_dataset,KEY2 = pai))\n",
    "    if not os.path.isfile(f'{nome_dataset}.arff'):\n",
    "    # File does not exist, create the ARFF file\n",
    "        pandas2arff(f'dataset_{nome_dataset}',f'{nome_dataset}.arff',f'{nome_dataset}')\n",
    "    else:\n",
    "        print(f'The file {nome_dataset} already exists.')\n",
    "    # exec('pandas2arff(dataset_{KEY},  \"{KEY}.arff\",\"{KEY}\")'.format(KEY = nome_dataset))  #can check first if part arff files are already created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7175913",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_glass = dataset_glass.rename(columns={\"'K'\": \"K\"}) # ajusting a different name in one collumn of glass dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f10488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(os.path.dirname(os.getcwd())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bd540b",
   "metadata": {},
   "source": [
    "## Storing arfffiles types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbb01f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading file: data\\raw\\abalone_classification.arff\n",
      "Number of instances: 4177\n",
      "Number of attributes: 9\n",
      "----------------------\n",
      "abalone_classification\n",
      "\n",
      "Loading file: data\\raw\\accent-mfcc-data-1.arff\n",
      "Number of instances: 329\n",
      "Number of attributes: 13\n",
      "----------------------\n",
      "accent_mfcc_data_1\n",
      "\n",
      "Loading file: data\\raw\\avila-tr.arff\n",
      "Number of instances: 10430\n",
      "Number of attributes: 11\n",
      "----------------------\n",
      "avila_tr\n",
      "\n",
      "Loading file: data\\raw\\avila-ts.arff\n",
      "Number of instances: 10437\n",
      "Number of attributes: 11\n",
      "----------------------\n",
      "avila_ts\n",
      "\n",
      "Loading file: data\\raw\\balance-scale.arff\n",
      "Number of instances: 625\n",
      "Number of attributes: 5\n",
      "----------------------\n",
      "balance_scale\n",
      "\n",
      "Loading file: data\\raw\\breast-cancer.arff\n",
      "Number of instances: 286\n",
      "Number of attributes: 10\n",
      "----------------------\n",
      "breast_cancer\n",
      "\n",
      "Loading file: data\\raw\\cmc.arff\n",
      "Number of instances: 1473\n",
      "Number of attributes: 10\n",
      "----------------------\n",
      "cmc\n",
      "\n",
      "Loading file: data\\raw\\contact-lenses.arff\n",
      "Number of instances: 24\n",
      "Number of attributes: 5\n",
      "----------------------\n",
      "contact_lenses\n",
      "\n",
      "Loading file: data\\raw\\credit-g.arff\n",
      "Number of instances: 1000\n",
      "Number of attributes: 21\n",
      "----------------------\n",
      "credit_g\n",
      "\n",
      "Loading file: data\\raw\\data_banknote_authentication.arff\n",
      "Number of instances: 1372\n",
      "Number of attributes: 5\n",
      "----------------------\n",
      "data_banknote_authentication\n",
      "\n",
      "Loading file: data\\raw\\diabetes.arff\n",
      "Number of instances: 768\n",
      "Number of attributes: 9\n",
      "----------------------\n",
      "diabetes\n",
      "\n",
      "Loading file: data\\raw\\DishonestInternetUsers.arff\n",
      "Number of instances: 322\n",
      "Number of attributes: 5\n",
      "----------------------\n",
      "DishonestInternetUsers\n",
      "\n",
      "Loading file: data\\raw\\ecoli.arff\n",
      "Number of instances: 336\n",
      "Number of attributes: 8\n",
      "----------------------\n",
      "ecoli\n",
      "\n",
      "Loading file: data\\raw\\EEG_Eye_State.arff\n",
      "Number of instances: 14980\n",
      "Number of attributes: 15\n",
      "----------------------\n",
      "EEG_Eye_State\n",
      "\n",
      "Loading file: data\\raw\\glass.arff\n",
      "Number of instances: 214\n",
      "Number of attributes: 10\n",
      "----------------------\n",
      "glass\n",
      "\n",
      "Loading file: data\\raw\\hayes-roth_trainAndtest.arff\n",
      "Number of instances: 160\n",
      "Number of attributes: 5\n",
      "----------------------\n",
      "hayes_roth_trainAndtest\n",
      "\n",
      "Loading file: data\\raw\\hcvdat0.arff\n",
      "Number of instances: 615\n",
      "Number of attributes: 13\n",
      "----------------------\n",
      "hcvdat0\n",
      "\n",
      "Loading file: data\\raw\\hypothyroid.arff\n",
      "Number of instances: 3772\n",
      "Number of attributes: 30\n",
      "----------------------\n",
      "hypothyroid\n",
      "\n",
      "Loading file: data\\raw\\ionosphere.arff\n",
      "Number of instances: 351\n",
      "Number of attributes: 35\n",
      "----------------------\n",
      "ionosphere\n",
      "\n",
      "Loading file: data\\raw\\iris.arff\n",
      "Number of instances: 150\n",
      "Number of attributes: 5\n",
      "----------------------\n",
      "iris\n",
      "\n",
      "Loading file: data\\raw\\labor.arff\n",
      "Number of instances: 57\n",
      "Number of attributes: 17\n",
      "----------------------\n",
      "labor\n",
      "\n",
      "Loading file: data\\raw\\magic04.arff\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 19020\n",
      "Number of attributes: 11\n",
      "----------------------\n",
      "magic04\n",
      "\n",
      "Loading file: data\\raw\\mammographic_masses.arff\n",
      "Number of instances: 961\n",
      "Number of attributes: 6\n",
      "----------------------\n",
      "mammographic_masses\n",
      "\n",
      "Loading file: data\\raw\\monks-1_train.arff\n",
      "Number of instances: 124\n",
      "Number of attributes: 7\n",
      "----------------------\n",
      "monks_1_train\n",
      "\n",
      "Loading file: data\\raw\\monks-2_train.arff\n",
      "Number of instances: 169\n",
      "Number of attributes: 7\n",
      "----------------------\n",
      "monks_2_train\n",
      "\n",
      "Loading file: data\\raw\\ObesityDataSet_raw_and_data_sinthetic.arff\n",
      "Number of instances: 2111\n",
      "Number of attributes: 17\n",
      "----------------------\n",
      "ObesityDataSet_raw_and_data_sinthetic\n",
      "\n",
      "Loading file: data\\raw\\seeds_dataset.arff\n",
      "Number of instances: 210\n",
      "Number of attributes: 8\n",
      "----------------------\n",
      "seeds_dataset\n",
      "\n",
      "Loading file: data\\raw\\segment-challenge.arff\n",
      "Number of instances: 1500\n",
      "Number of attributes: 20\n",
      "----------------------\n",
      "segment_challenge\n",
      "\n",
      "Loading file: data\\raw\\sonar_all-data.arff\n",
      "Number of instances: 208\n",
      "Number of attributes: 61\n",
      "----------------------\n",
      "sonar_all_data\n",
      "\n",
      "Loading file: data\\raw\\soybean.arff\n",
      "Number of instances: 683\n",
      "Number of attributes: 36\n",
      "----------------------\n",
      "soybean\n",
      "\n",
      "Loading file: data\\raw\\Surveillance.arff\n",
      "Number of instances: 14\n",
      "Number of attributes: 8\n",
      "----------------------\n",
      "Surveillance\n",
      "\n",
      "Loading file: data\\raw\\vote.arff\n",
      "Number of instances: 435\n",
      "Number of attributes: 17\n",
      "----------------------\n",
      "vote\n",
      "\n",
      "Loading file: data\\raw\\weather_nominal.arff\n",
      "Number of instances: 14\n",
      "Number of attributes: 5\n",
      "----------------------\n",
      "weather_nominal\n",
      "\n",
      "Loading file: data\\raw\\wifi_localization.arff\n",
      "Number of instances: 2000\n",
      "Number of attributes: 8\n",
      "----------------------\n",
      "wifi_localization\n",
      "\n",
      "Loading file: data\\raw\\wilt.arff\n",
      "Number of instances: 4839\n",
      "Number of attributes: 6\n",
      "----------------------\n",
      "wilt\n",
      "\n",
      "Loading file: data\\raw\\wine.arff\n",
      "Number of instances: 178\n",
      "Number of attributes: 14\n",
      "----------------------\n",
      "wine\n",
      "\n",
      "Loading file: data\\raw\\winequality-red_classification.arff\n",
      "Number of instances: 1599\n",
      "Number of attributes: 12\n",
      "----------------------\n",
      "winequality_red_classification\n",
      "\n",
      "Loading file: data\\raw\\winequality-white_classification.arff\n",
      "Number of instances: 4898\n",
      "Number of attributes: 12\n",
      "----------------------\n",
      "winequality_white_classification\n",
      "\n",
      "Loading file: data\\raw\\yeast.arff\n",
      "Number of instances: 1484\n",
      "Number of attributes: 9\n",
      "----------------------\n",
      "yeast\n",
      "\n",
      "Loading file: data\\raw\\zoo.arff\n",
      "Number of instances: 101\n",
      "Number of attributes: 17\n",
      "----------------------\n",
      "zoo\n"
     ]
    }
   ],
   "source": [
    "arff_files_dict={}\n",
    "# Set the path to the folder containing ARFF files\n",
    "folder_path = \"data\\\\raw\"  # Replace with your folder path\n",
    "\n",
    "# Iterate over the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if os.path.isfile(file_path) and filename.endswith(\".arff\"):\n",
    "        print(\"\\nLoading file:\", file_path)\n",
    "        try:\n",
    "            data = converters.load_any_file(file_path)\n",
    "            \n",
    "            # Perform further processing or analysis on the data\n",
    "            # ...\n",
    "            # Your code here\n",
    "            \n",
    "            # Example: Print the dataset summary\n",
    "            print(\"Number of instances:\", data.num_instances)\n",
    "            print(\"Number of attributes:\", data.num_attributes)\n",
    "            print(\"----------------------\")\n",
    "\n",
    "            nome = filename.split(\"\\\\\")[-1]\n",
    "            nome = nome.replace(\".arff\", \"\")\n",
    "            nome = nome.replace(\"-\", \"_\")\n",
    "            print(nome)\n",
    "            exec('arff_files_dict[\"{KEY}\"] = data'.format(KEY = nome))\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Error loading file:\", file_path)\n",
    "            print(\"Error message:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92d9e5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading file: data\\interim\\credit_g_part1.arff\n",
      "Number of instances: 1000\n",
      "Number of attributes: 11\n",
      "----------------------\n",
      "credit_g_part1\n",
      "\n",
      "Loading file: data\\interim\\credit_g_part2.arff\n",
      "Number of instances: 1000\n",
      "Number of attributes: 11\n",
      "----------------------\n",
      "credit_g_part2\n",
      "\n",
      "Loading file: data\\interim\\hypothyroid_part1.arff\n",
      "Number of instances: 3772\n",
      "Number of attributes: 11\n",
      "----------------------\n",
      "hypothyroid_part1\n",
      "\n",
      "Loading file: data\\interim\\hypothyroid_part2.arff\n",
      "Number of instances: 3772\n",
      "Number of attributes: 11\n",
      "----------------------\n",
      "hypothyroid_part2\n",
      "\n",
      "Loading file: data\\interim\\hypothyroid_part3.arff\n",
      "Number of instances: 3772\n",
      "Number of attributes: 10\n",
      "----------------------\n",
      "hypothyroid_part3\n",
      "\n",
      "Loading file: data\\interim\\ionosphere_part1.arff\n",
      "Number of instances: 351\n",
      "Number of attributes: 13\n",
      "----------------------\n",
      "ionosphere_part1\n",
      "\n",
      "Loading file: data\\interim\\ionosphere_part2.arff\n",
      "Number of instances: 351\n",
      "Number of attributes: 12\n",
      "----------------------\n",
      "ionosphere_part2\n",
      "\n",
      "Loading file: data\\interim\\ionosphere_part3.arff\n",
      "Number of instances: 351\n",
      "Number of attributes: 12\n",
      "----------------------\n",
      "ionosphere_part3\n",
      "\n",
      "Loading file: data\\interim\\labor_part1.arff\n",
      "Number of instances: 57\n",
      "Number of attributes: 9\n",
      "----------------------\n",
      "labor_part1\n",
      "\n",
      "Loading file: data\\interim\\labor_part2.arff\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 57\n",
      "Number of attributes: 9\n",
      "----------------------\n",
      "labor_part2\n",
      "\n",
      "Loading file: data\\interim\\segment_challenge_part1.arff\n",
      "Number of instances: 1500\n",
      "Number of attributes: 11\n",
      "----------------------\n",
      "segment_challenge_part1\n",
      "\n",
      "Loading file: data\\interim\\segment_challenge_part2.arff\n",
      "Number of instances: 1500\n",
      "Number of attributes: 10\n",
      "----------------------\n",
      "segment_challenge_part2\n",
      "\n",
      "Loading file: data\\interim\\sonar_all_data_part1.arff\n",
      "Number of instances: 208\n",
      "Number of attributes: 13\n",
      "----------------------\n",
      "sonar_all_data_part1\n",
      "\n",
      "Loading file: data\\interim\\sonar_all_data_part2.arff\n",
      "Number of instances: 208\n",
      "Number of attributes: 13\n",
      "----------------------\n",
      "sonar_all_data_part2\n",
      "\n",
      "Loading file: data\\interim\\sonar_all_data_part3.arff\n",
      "Number of instances: 208\n",
      "Number of attributes: 13\n",
      "----------------------\n",
      "sonar_all_data_part3\n",
      "\n",
      "Loading file: data\\interim\\sonar_all_data_part4.arff\n",
      "Number of instances: 208\n",
      "Number of attributes: 13\n",
      "----------------------\n",
      "sonar_all_data_part4\n",
      "\n",
      "Loading file: data\\interim\\sonar_all_data_part5.arff\n",
      "Number of instances: 208\n",
      "Number of attributes: 13\n",
      "----------------------\n",
      "sonar_all_data_part5\n",
      "\n",
      "Loading file: data\\interim\\soybean_part1.arff\n",
      "Number of instances: 683\n",
      "Number of attributes: 13\n",
      "----------------------\n",
      "soybean_part1\n",
      "\n",
      "Loading file: data\\interim\\soybean_part2.arff\n",
      "Number of instances: 683\n",
      "Number of attributes: 13\n",
      "----------------------\n",
      "soybean_part2\n",
      "\n",
      "Loading file: data\\interim\\soybean_part3.arff\n",
      "Number of instances: 683\n",
      "Number of attributes: 12\n",
      "----------------------\n",
      "soybean_part3\n",
      "\n",
      "Loading file: data\\interim\\vote_part1.arff\n",
      "Number of instances: 435\n",
      "Number of attributes: 9\n",
      "----------------------\n",
      "vote_part1\n",
      "\n",
      "Loading file: data\\interim\\vote_part2.arff\n",
      "Number of instances: 435\n",
      "Number of attributes: 9\n",
      "----------------------\n",
      "vote_part2\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the folder containing ARFF files\n",
    "folder_path = \"data\\\\interim\"  # Replace with your folder path\n",
    "\n",
    "# Iterate over the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if os.path.isfile(file_path) and filename.endswith(\".arff\"):\n",
    "        print(\"\\nLoading file:\", file_path)\n",
    "        try:\n",
    "            data = converters.load_any_file(file_path)\n",
    "            \n",
    "            # Perform further processing or analysis on the data\n",
    "            # ...\n",
    "            # Your code here\n",
    "            \n",
    "            # Example: Print the dataset summary\n",
    "            print(\"Number of instances:\", data.num_instances)\n",
    "            print(\"Number of attributes:\", data.num_attributes)\n",
    "            print(\"----------------------\")\n",
    "\n",
    "            nome = filename.split(\"\\\\\")[-1]\n",
    "            nome = nome.replace(\".arff\", \"\")\n",
    "            nome = nome.replace(\"-\", \"_\")\n",
    "            print(nome)\n",
    "            exec('arff_files_dict[\"{KEY}\"] = data'.format(KEY = nome))\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Error loading file:\", file_path)\n",
    "            print(\"Error message:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5de395",
   "metadata": {},
   "source": [
    "# Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8609799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "\n",
    "def descriptors(data,data_encoded):\n",
    "    # perform attribute selection\n",
    "    search = ASSearch(classname=\"weka.attributeSelection.Ranker\", options=[\"-N\", \"-1\"])\n",
    "    evaluation = ASEvaluation(classname=\"weka.attributeSelection.PrincipalComponents\", options=[\"-R\", \"1.00\"]) #, options=[\"-A\", \"-1\"]\n",
    "    attsel = AttributeSelection()\n",
    "    attsel.search(search)\n",
    "    attsel.evaluator(evaluation)\n",
    "    attsel.select_attributes(data_encoded)\n",
    "\n",
    "    # Sample string containing the information\n",
    "    sample_string = attsel.results_string\n",
    "  \n",
    "    \n",
    "\n",
    "    # Regular expressions to extract the required information\n",
    "    correlation_pattern = r'Correlation matrix(.*?)\\n\\n'\n",
    "\n",
    "    # Extracting the relevant information\n",
    "    correlation_matrix = re.search(correlation_pattern, sample_string, re.DOTALL).group(1)\n",
    "\n",
    "    # Splitting the values and creating lists\n",
    "    correlation_values = [list(map(float, line.split())) for line in correlation_matrix.strip().split('\\n')[:]]\n",
    "\n",
    "    # Create DataFrames\n",
    "    correlation_df = pd.DataFrame(correlation_values)\n",
    "\n",
    "    # Descriptor dsMatrixCorrelSD \n",
    "    dsMatrixCorrelSD = np.std(correlation_df.values,ddof=1)\n",
    "\n",
    "#     # perform attribute selection\n",
    "#     search = ASSearch(classname=\"weka.attributeSelection.Ranker\", options=[\"-N\", \"-1\"])\n",
    "#     evaluation = ASEvaluation(classname=\"weka.attributeSelection.PrincipalComponents\", options=[\"-R\", \"1.00\"]) #, options=[\"-A\", \"-1\"]\n",
    "#     attsel = AttributeSelection()\n",
    "#     attsel.search(search)\n",
    "#     attsel.evaluator(evaluation)\n",
    "#     attsel.select_attributes(data)\n",
    "#     # Sample string containing the information\n",
    "#     sample_string = attsel.results_string\n",
    "        \n",
    "    # Sample string containing the information\n",
    "#     sample_string = attsel.results_string\n",
    "\n",
    "    # Regular expressions to extract the required information\n",
    "    proportion_pattern = r'\\n\\n\\neigenvalue\\tproportion\\tcumulative\\n(.*?)\\n\\n'\n",
    "\n",
    "    # Extracting the relevant information\n",
    "    proportion_cumulative = re.search(proportion_pattern, sample_string, re.DOTALL).group(1)\n",
    "\n",
    "    # Splitting the values and creating lists\n",
    "    a=[]\n",
    "    for line in proportion_cumulative.strip().split('\\n'):\n",
    "        for field in line.split('\\t'):\n",
    "            try:\n",
    "                a.append(float(field))\n",
    "    #             print(a)\n",
    "            except:\n",
    "                pass\n",
    "    #             print(\"erro\")    \n",
    "    #   proportion_cumulative_values = [list(map(float, line.split('\\t'))) for line in proportion_cumulative.strip().split('\\n')]\n",
    "    # Reshape the list into chunks of 3\n",
    "    num_columns=3\n",
    "    reshaped_values = [a[i:i + num_columns] for i in range(0, len(a), num_columns)]\n",
    "\n",
    "    # Create a DataFrame\n",
    "    proportion_cumulative_df = pd.DataFrame(reshaped_values, columns=['eigenvalue', 'proportion', 'cumulative'])\n",
    "\n",
    "\n",
    "\n",
    "    # dsEigenvaluePropIntercept\n",
    "    reg_prop = LinearRegression().fit((proportion_cumulative_df.index.values +1).reshape(-1, 1),proportion_cumulative_df.proportion.values)\n",
    "    dsEigenvaluePropIntercept = reg_prop.intercept_\n",
    "\n",
    "    # dsEigenvalueCumulativeIntercept\n",
    "    reg_cumulative = LinearRegression().fit((proportion_cumulative_df.index.values +1).reshape(-1, 1),proportion_cumulative_df.cumulative.values)\n",
    "    dsEigenvalueCumulativeIntercept = reg_cumulative.intercept_\n",
    "    \n",
    "    \n",
    "#     # dsEigenvaluePropIntercept\n",
    "#     x = proportion_cumulative_df.index.values +1\n",
    "#     print('x:',x)\n",
    "#     y = proportion_cumulative_df.proportion.values\n",
    "#     print('y:',y)\n",
    "#     res = stats.linregress(x, y)\n",
    "#     print('intercept:',res.intercept)    \n",
    "    \n",
    "#     # dsEigenvalueCumulativeIntercept\n",
    "#     x = proportion_cumulative_df.index.values +1\n",
    "#     print('x:',x)\n",
    "#     y = proportion_cumulative_df.cumulative.values\n",
    "#     print('y:',y)\n",
    "#     res = stats.linregress(x, y)\n",
    "#     print('intercept:',res.intercept)    \n",
    "    \n",
    "    \n",
    "\n",
    "    # perform attribute selection\n",
    "    search = ASSearch(classname=\"weka.attributeSelection.Ranker\", options=[\"-N\", \"-1\"])\n",
    "    evaluation = ASEvaluation(classname=\"weka.attributeSelection.ChiSquaredAttributeEval\")\n",
    "    attsel = AttributeSelection()\n",
    "    attsel.search(search)\n",
    "    attsel.evaluator(evaluation)\n",
    "    attsel.select_attributes(data)\n",
    "\n",
    "    # dsChiSquaredMax\n",
    "    dsChiSquaredMax = attsel.ranked_attributes[0][1]\n",
    "\n",
    "    # Sample string containing the information\n",
    "    sample_string = attsel.results_string\n",
    "\n",
    "    # Regular expressions to extract the required information\n",
    "    chisquare_pattern = r'\\n\\nRanked attributes:(.*?)\\n\\n'\n",
    "\n",
    "    # Extracting the relevant information\n",
    "    chisquare = re.search(chisquare_pattern, sample_string, re.DOTALL).group(1)\n",
    "    \n",
    "    # Splitting the values and creating lists\n",
    "    lines = chisquare.strip().split('\\n')\n",
    "    aux = [line.split(None, 2) for line in lines]\n",
    "\n",
    "    # Create a DataFrame from the list of lists\n",
    "    chisquare_df = pd.DataFrame(aux, columns=['chisquare', 'rank', 'attribute'])\n",
    "    chisquare_df['chisquare'] = chisquare_df['chisquare'].astype(float)\n",
    "    chisquare_df['rank'] = chisquare_df['rank'].astype(int)\n",
    "    chisquare_df.chisquare = chisquare_df.chisquare/max(chisquare_df.chisquare)\n",
    "    \n",
    "#     # Splitting the values and creating lists\n",
    "#     a=[]\n",
    "#     for line in chisquare.strip().split('\\n'):\n",
    "#         print('line:',line)\n",
    "#         for field in line.split():\n",
    "#             print('field:',field)\n",
    "#             try:\n",
    "#                 a.append(float(field))\n",
    "#     #             print(a)\n",
    "#             except:\n",
    "#                 a.append(field)\n",
    "#     #             print(\"erro\")    \n",
    "#     #   proportion_cumulative_values = [list(map(float, line.split('\\t'))) for line in proportion_cumulative.strip().split('\\n')]\n",
    "\n",
    "#     # Reshape the list into chunks of 3\n",
    "#     num_columns=3\n",
    "#     reshaped_values = [a[i:i + num_columns] for i in range(0, len(a), num_columns)]\n",
    "\n",
    "#     # Create a DataFrame\n",
    "#     chisquare_df = pd.DataFrame(reshaped_values, columns=['chisquare', 'rank', 'attribute'])\n",
    "#     print(chisquare_df)\n",
    "#     chisquare_df.chisquare = chisquare_df.chisquare/max(chisquare_df.chisquare)\n",
    "\n",
    "    # attChiSquaredNormalized\n",
    "    attChiSquaredNormalized = chisquare_df.drop(['rank'], axis=1)\n",
    "\n",
    "    # perform attribute selection\n",
    "    search = ASSearch(classname=\"weka.attributeSelection.Ranker\", options=[\"-N\", \"-1\"])\n",
    "    evaluation = ASEvaluation(classname=\"weka.attributeSelection.ClassifierAttributeEval\", options=[\"-B\", \"weka.classifiers.functions.SimpleLogistic\"]) #, options=[\"-A\", \"-1\"]\n",
    "    attsel = AttributeSelection()\n",
    "    attsel.search(search)\n",
    "    attsel.evaluator(evaluation)\n",
    "    attsel.select_attributes(data)\n",
    "\n",
    "    # Sample string containing the information\n",
    "    sample_string = attsel.results_string\n",
    "\n",
    "    # Regular expressions to extract the required information\n",
    "    classif_log_pattern = r'\\nRanked attributes:(.*?)\\n\\n'\n",
    "\n",
    "    # Extracting the relevant information\n",
    "    classif_log = re.search(classif_log_pattern, sample_string, re.DOTALL).group(1)\n",
    "    \n",
    "    # Splitting the values and creating lists\n",
    "    lines = classif_log.strip().split('\\n')\n",
    "    aux = [line.split(None, 2) for line in lines]\n",
    "\n",
    "    # Create a DataFrame from the list of lists\n",
    "    classif_log_df = pd.DataFrame(aux, columns=['classif_log', 'rank', 'attribute'])\n",
    "    classif_log_df['classif_log'] = classif_log_df['classif_log'].astype(float)\n",
    "    classif_log_df['rank'] = classif_log_df['rank'].astype(int)\n",
    "    classif_log_df.classif_log = classif_log_df.classif_log/max(classif_log_df.classif_log)\n",
    "\n",
    "#     # Splitting the values and creating lists\n",
    "#     a=[]\n",
    "#     for line in classif_log.strip().split('\\n'):\n",
    "#         for field in line.split():\n",
    "#             try:\n",
    "#                 a.append(float(field))\n",
    "#     #             print(a)\n",
    "#             except:\n",
    "#                 a.append(field)\n",
    "#     #             print(\"erro\")    \n",
    "#     #   proportion_cumulative_values = [list(map(float, line.split('\\t'))) for line in proportion_cumulative.strip().split('\\n')]\n",
    "\n",
    "#     # Reshape the list into chunks of 3\n",
    "#     num_columns=3\n",
    "#     reshaped_values = [a[i:i + num_columns] for i in range(0, len(a), num_columns)]\n",
    "\n",
    "#     # Create a DataFrame\n",
    "#     classif_log_df = pd.DataFrame(reshaped_values, columns=['classif_log', 'rank', 'attribute'])\n",
    "#     classif_log_df.classif_log = classif_log_df.classif_log/max(classif_log_df.classif_log)\n",
    "\n",
    "    # attClassifierLogisticNormalized\n",
    "    attClassifierLogisticNormalized = classif_log_df.drop(['rank'], axis=1)\n",
    "\n",
    "    # perform attribute selection\n",
    "    search = ASSearch(classname=\"weka.attributeSelection.Ranker\", options=[\"-N\", \"-1\"])\n",
    "    evaluation = ASEvaluation(classname=\"weka.attributeSelection.CorrelationAttributeEval\") #, options=[\"-A\", \"-1\"]\n",
    "    attsel = AttributeSelection()\n",
    "    attsel.search(search)\n",
    "    attsel.evaluator(evaluation)\n",
    "    attsel.select_attributes(data)\n",
    "\n",
    "    # Sample string containing the information\n",
    "    sample_string = attsel.results_string\n",
    "\n",
    "    # Regular expressions to extract the required information\n",
    "    correlation_pattern = r'\\nRanked attributes:(.*?)\\n\\n'\n",
    "\n",
    "    # Extracting the relevant information\n",
    "    correlation = re.search(correlation_pattern, sample_string, re.DOTALL).group(1)\n",
    "    \n",
    "    # Splitting the values and creating lists\n",
    "    lines = correlation.strip().split('\\n')\n",
    "    aux = [line.split(None, 2) for line in lines]\n",
    "\n",
    "    # Create a DataFrame from the list of lists\n",
    "    correlation_df = pd.DataFrame(aux, columns=['correlation', 'rank', 'attribute'])\n",
    "    correlation_df['correlation'] = correlation_df['correlation'].astype(float)\n",
    "    correlation_df['rank'] = correlation_df['rank'].astype(int)\n",
    "    correlation_df.correlation = correlation_df.correlation/max(correlation_df.correlation)\n",
    "\n",
    "#     # Splitting the values and creating lists\n",
    "#     a=[]\n",
    "#     for line in correlation.strip().split('\\n'):\n",
    "#         for field in line.split():\n",
    "#             try:\n",
    "#                 a.append(float(field))\n",
    "#     #             print(a)\n",
    "#             except:\n",
    "#                 a.append(field)\n",
    "#     #             print(\"erro\")    \n",
    "#     #   proportion_cumulative_values = [list(map(float, line.split('\\t'))) for line in proportion_cumulative.strip().split('\\n')]\n",
    "\n",
    "#     # Reshape the list into chunks of 3\n",
    "#     num_columns=3\n",
    "#     reshaped_values = [a[i:i + num_columns] for i in range(0, len(a), num_columns)]\n",
    "\n",
    "#     # Create a DataFrame\n",
    "#     correlation_df = pd.DataFrame(reshaped_values, columns=['correlation', 'rank', 'attribute'])\n",
    "#     correlation_df.correlation = correlation_df.correlation/max(correlation_df.correlation)\n",
    "\n",
    "    # attCorrelationNormalized\n",
    "    attCorrelationNormalized = correlation_df.drop(['rank'], axis=1)\n",
    "\n",
    "    # perform attribute selection\n",
    "    search = ASSearch(classname=\"weka.attributeSelection.Ranker\", options=[\"-N\", \"-1\"])\n",
    "    evaluation = ASEvaluation(classname=\"weka.attributeSelection.ReliefFAttributeEval\") #, options=[\"-A\", \"-1\"]\n",
    "    attsel = AttributeSelection()\n",
    "    attsel.search(search)\n",
    "    attsel.evaluator(evaluation)\n",
    "    attsel.select_attributes(data)\n",
    "\n",
    "    # Sample string containing the information\n",
    "    sample_string = attsel.results_string\n",
    "\n",
    "    # Regular expressions to extract the required information\n",
    "    reliefF_pattern = r'\\n\\nRanked attributes:(.*?)\\n\\n'\n",
    "\n",
    "    # Extracting the relevant information\n",
    "    relief = re.search(reliefF_pattern, sample_string, re.DOTALL).group(1)\n",
    "    \n",
    "    # Splitting the values and creating lists\n",
    "    lines = relief.strip().split('\\n')\n",
    "    aux = [line.split(None, 2) for line in lines]\n",
    "\n",
    "    # Create a DataFrame from the list of lists\n",
    "    relief_df = pd.DataFrame(aux, columns=['reliefF', 'rank', 'attribute'])\n",
    "    relief_df['reliefF'] = relief_df['reliefF'].astype(float)\n",
    "    relief_df['rank'] = relief_df['rank'].astype(int)\n",
    "    relief_df.reliefF = relief_df.reliefF/max(relief_df.reliefF)\n",
    "\n",
    "#     # Splitting the values and creating lists\n",
    "#     a=[]\n",
    "#     for line in relief.strip().split('\\n'):\n",
    "#         for field in line.split():\n",
    "#             try:\n",
    "#                 a.append(float(field))\n",
    "#     #             print(a)\n",
    "#             except:\n",
    "#                 a.append(field)\n",
    "#     #             print(\"erro\")    \n",
    "#     #   proportion_cumulative_values = [list(map(float, line.split('\\t'))) for line in proportion_cumulative.strip().split('\\n')]\n",
    "\n",
    "#     # Reshape the list into chunks of 3\n",
    "#     num_columns=3\n",
    "#     reshaped_values = [a[i:i + num_columns] for i in range(0, len(a), num_columns)]\n",
    "\n",
    "#     # Create a DataFrame\n",
    "#     relief_df = pd.DataFrame(reshaped_values, columns=['reliefF', 'rank', 'attribute'])\n",
    "#     relief_df.reliefF = relief_df.reliefF/max(relief_df.reliefF)\n",
    "\n",
    "    # attReliefFNormalized\n",
    "    attReliefFNormalized = relief_df.drop(['rank'], axis=1)\n",
    "\n",
    "    # perform attribute selection\n",
    "    search = ASSearch(classname=\"weka.attributeSelection.Ranker\", options=[\"-N\", \"-1\"])\n",
    "    evaluation = ASEvaluation(classname=\"weka.attributeSelection.SymmetricalUncertAttributeEval\") #, options=[\"-A\", \"-1\"]\n",
    "    attsel = AttributeSelection()\n",
    "    attsel.search(search)\n",
    "    attsel.evaluator(evaluation)\n",
    "    attsel.select_attributes(data)\n",
    "\n",
    "    # Sample string containing the information\n",
    "    sample_string = attsel.results_string\n",
    "\n",
    "    # Regular expressions to extract the required information\n",
    "    sym_uncert_pattern = r'\\n\\nRanked attributes:(.*?)\\n\\n'\n",
    "\n",
    "    # Extracting the relevant information\n",
    "    sym_uncert = re.search(sym_uncert_pattern, sample_string, re.DOTALL).group(1)\n",
    "    \n",
    "    # Splitting the values and creating lists\n",
    "    lines = sym_uncert.strip().split('\\n')\n",
    "    aux = [line.split(None, 2) for line in lines]\n",
    "\n",
    "    # Create a DataFrame from the list of lists\n",
    "    sym_uncert_df = pd.DataFrame(aux, columns=['sym_uncert', 'rank', 'attribute'])\n",
    "    sym_uncert_df['sym_uncert'] = sym_uncert_df['sym_uncert'].astype(float)\n",
    "    sym_uncert_df['rank'] = sym_uncert_df['rank'].astype(int)\n",
    "    sym_uncert_df.sym_uncert = sym_uncert_df.sym_uncert/max(sym_uncert_df.sym_uncert)\n",
    "\n",
    "#     # Splitting the values and creating lists\n",
    "#     a=[]\n",
    "#     for line in sym_uncert.strip().split('\\n'):\n",
    "#         for field in line.split():\n",
    "#             try:\n",
    "#                 a.append(float(field))\n",
    "#         #             print(a)\n",
    "#             except:\n",
    "#                 a.append(field)\n",
    "#     #             print(\"erro\")    \n",
    "#     #   proportion_cumulative_values = [list(map(float, line.split('\\t'))) for line in proportion_cumulative.strip().split('\\n')]\n",
    "\n",
    "#     # Reshape the list into chunks of 3\n",
    "#     num_columns=3\n",
    "#     reshaped_values = [a[i:i + num_columns] for i in range(0, len(a), num_columns)]\n",
    "\n",
    "#     # Create a DataFrame\n",
    "#     sym_uncert_df = pd.DataFrame(reshaped_values, columns=['sym_uncert', 'rank', 'attribute'])\n",
    "#     sym_uncert_df.sym_uncert = sym_uncert_df.sym_uncert/max(sym_uncert_df.sym_uncert)\n",
    "\n",
    "    # attSymmetricalUncertNormalized\n",
    "    attSymmetricalUncertNormalized = sym_uncert_df.drop(['rank'], axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #dsLOGnInstances\n",
    "    dsLOGnInstances = np.log10(data.num_instances)    \n",
    "    \n",
    "    #dsLnNumClasses\n",
    "    dsLnNumClasses = np.log(data.attribute(data.class_index).num_values)\n",
    "    \n",
    "#     final_df = attChiSquaredNormalized.copy()\n",
    "    \n",
    "\n",
    "    final_df = pd.merge(attChiSquaredNormalized,attClassifierLogisticNormalized,on='attribute')\n",
    "    final_df = pd.merge(final_df,attCorrelationNormalized,on='attribute')\n",
    "    final_df = pd.merge(final_df,attReliefFNormalized,on='attribute')\n",
    "    final_df = pd.merge(final_df,attSymmetricalUncertNormalized,on='attribute') \n",
    "    \n",
    "    final_df = final_df.rename(columns={\"chisquare\": \"attChiSquaredNormalized\", \"classif_log\": \"attClassifierLogisticNormalized\",\"correlation\": \"attCorrelationNormalized\", \"reliefF\": \"attReliefFNormalized\",\"sym_uncert\": \"attSymmetricalUncertNormalized\"})\n",
    "    \n",
    "    final_df['dsMatrixCorrelSD'] = dsMatrixCorrelSD\n",
    "    final_df['dsEigenvaluePropIntercept'] = dsEigenvaluePropIntercept    \n",
    "    final_df['dsEigenvalueCumulativeIntercept'] = dsEigenvalueCumulativeIntercept\n",
    "    final_df['dsChiSquaredMax'] = dsChiSquaredMax\n",
    "    final_df['dsLOGnInstances'] = dsLOGnInstances\n",
    "    final_df['dsLnNumClasses'] = dsLnNumClasses\n",
    "    \n",
    "    \n",
    "    \n",
    "    final_df= final_df[['dsMatrixCorrelSD','dsEigenvaluePropIntercept','dsEigenvalueCumulativeIntercept','dsChiSquaredMax','attChiSquaredNormalized','attClassifierLogisticNormalized','attCorrelationNormalized','attReliefFNormalized','attSymmetricalUncertNormalized','dsLOGnInstances','dsLnNumClasses','attribute']]\n",
    "    \n",
    "    \n",
    "#     final_df.merge(attClassifierLogisticNormalized, on='attribute', how='left')\n",
    "#     final_df.merge(attCorrelationNormalized, on='attribute', how='left')\n",
    "#     final_df.merge(attReliefFNormalized, on='attribute', how='left')    \n",
    "#     final_df.merge(attSymmetricalUncertNormalized, on='attribute', how='left')      \n",
    "    \n",
    "#     return [dsMatrixCorrelSD,dsEigenvaluePropIntercept,dsEigenvalueCumulativeIntercept,dsChiSquaredMax,attChiSquaredNormalized,attClassifierLogisticNormalized,attCorrelationNormalized,attReliefFNormalized,attSymmetricalUncertNormalized,dsLOGnInstances,dsLnNumClasses,final_df]    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da90dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weka.core.dataset import Instances\n",
    "descriptors_df = pd.DataFrame()\n",
    "datasets_descriptors =list(groups.unique())\n",
    "for i in datasets_descriptors:\n",
    "    exec('dataset_arff = arff_files_dict[\"{KEY}\"]'.format(KEY = i))    \n",
    "    dataset0 = Instances.copy_instances(dataset_arff)  # Copy instances from dataset\n",
    "    dataset0.class_is_last()   # set class attribute\n",
    "    # load a dataset\n",
    "    dataset1 = Instances.copy_instances(dataset_arff)  # Copy instances from dataset\n",
    "    aux = descriptors(dataset0,dataset1)\n",
    "    aux['datasetName'] = i\n",
    "    descriptors_df = pd.concat([descriptors_df, aux], ignore_index=True)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5b5480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_df['attribute'] = descriptors_df['attribute'].str.replace(\" \", \"_\")\n",
    "descriptors_df['datasetName'] = descriptors_df['datasetName'].str.replace(\"-\", \"_\")\n",
    "descriptors_df = descriptors_df.rename(columns={'attribute': 'attributeName'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d907dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dsMatrixCorrelSD</th>\n",
       "      <th>dsEigenvaluePropIntercept</th>\n",
       "      <th>dsEigenvalueCumulativeIntercept</th>\n",
       "      <th>dsChiSquaredMax</th>\n",
       "      <th>attChiSquaredNormalized</th>\n",
       "      <th>attClassifierLogisticNormalized</th>\n",
       "      <th>attCorrelationNormalized</th>\n",
       "      <th>attReliefFNormalized</th>\n",
       "      <th>attSymmetricalUncertNormalized</th>\n",
       "      <th>dsLOGnInstances</th>\n",
       "      <th>dsLnNumClasses</th>\n",
       "      <th>attributeName</th>\n",
       "      <th>datasetName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666645</td>\n",
       "      <td>0.493463</td>\n",
       "      <td>0.719181</td>\n",
       "      <td>268.419048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954787</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>2.176091</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>petallength</td>\n",
       "      <td>iris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666645</td>\n",
       "      <td>0.493463</td>\n",
       "      <td>0.719181</td>\n",
       "      <td>268.419048</td>\n",
       "      <td>0.994371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.176091</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>petalwidth</td>\n",
       "      <td>iris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666645</td>\n",
       "      <td>0.493463</td>\n",
       "      <td>0.719181</td>\n",
       "      <td>268.419048</td>\n",
       "      <td>0.470954</td>\n",
       "      <td>0.657097</td>\n",
       "      <td>0.777236</td>\n",
       "      <td>0.372340</td>\n",
       "      <td>0.469575</td>\n",
       "      <td>2.176091</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>sepallength</td>\n",
       "      <td>iris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666645</td>\n",
       "      <td>0.493463</td>\n",
       "      <td>0.719181</td>\n",
       "      <td>268.419048</td>\n",
       "      <td>0.263171</td>\n",
       "      <td>0.357257</td>\n",
       "      <td>0.645528</td>\n",
       "      <td>0.324468</td>\n",
       "      <td>0.275545</td>\n",
       "      <td>2.176091</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>sepalwidth</td>\n",
       "      <td>iris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.406496</td>\n",
       "      <td>0.216496</td>\n",
       "      <td>0.398940</td>\n",
       "      <td>15.064286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878689</td>\n",
       "      <td>0.956530</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.755875</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>wage-increase-second-year</td>\n",
       "      <td>labor_part1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.381562</td>\n",
       "      <td>0.156774</td>\n",
       "      <td>0.517723</td>\n",
       "      <td>208.165859</td>\n",
       "      <td>0.222956</td>\n",
       "      <td>0.350015</td>\n",
       "      <td>0.463506</td>\n",
       "      <td>0.363265</td>\n",
       "      <td>0.383380</td>\n",
       "      <td>2.004321</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>aquatic</td>\n",
       "      <td>zoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.381562</td>\n",
       "      <td>0.156774</td>\n",
       "      <td>0.517723</td>\n",
       "      <td>208.165859</td>\n",
       "      <td>0.178550</td>\n",
       "      <td>0.249975</td>\n",
       "      <td>0.555631</td>\n",
       "      <td>0.366118</td>\n",
       "      <td>0.299295</td>\n",
       "      <td>2.004321</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>catsize</td>\n",
       "      <td>zoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.381562</td>\n",
       "      <td>0.156774</td>\n",
       "      <td>0.517723</td>\n",
       "      <td>208.165859</td>\n",
       "      <td>0.091768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297375</td>\n",
       "      <td>0.046668</td>\n",
       "      <td>0.156368</td>\n",
       "      <td>2.004321</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>venomous</td>\n",
       "      <td>zoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.381562</td>\n",
       "      <td>0.156774</td>\n",
       "      <td>0.517723</td>\n",
       "      <td>208.165859</td>\n",
       "      <td>0.058555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154953</td>\n",
       "      <td>0.105274</td>\n",
       "      <td>0.090641</td>\n",
       "      <td>2.004321</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>predator</td>\n",
       "      <td>zoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.381562</td>\n",
       "      <td>0.156774</td>\n",
       "      <td>0.517723</td>\n",
       "      <td>208.165859</td>\n",
       "      <td>0.023116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170703</td>\n",
       "      <td>-0.003189</td>\n",
       "      <td>0.056384</td>\n",
       "      <td>2.004321</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>domestic</td>\n",
       "      <td>zoo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dsMatrixCorrelSD  dsEigenvaluePropIntercept  \\\n",
       "0            0.666645                   0.493463   \n",
       "1            0.666645                   0.493463   \n",
       "2            0.666645                   0.493463   \n",
       "3            0.666645                   0.493463   \n",
       "4            0.406496                   0.216496   \n",
       "..                ...                        ...   \n",
       "488          0.381562                   0.156774   \n",
       "489          0.381562                   0.156774   \n",
       "490          0.381562                   0.156774   \n",
       "491          0.381562                   0.156774   \n",
       "492          0.381562                   0.156774   \n",
       "\n",
       "     dsEigenvalueCumulativeIntercept  dsChiSquaredMax  \\\n",
       "0                           0.719181       268.419048   \n",
       "1                           0.719181       268.419048   \n",
       "2                           0.719181       268.419048   \n",
       "3                           0.719181       268.419048   \n",
       "4                           0.398940        15.064286   \n",
       "..                               ...              ...   \n",
       "488                         0.517723       208.165859   \n",
       "489                         0.517723       208.165859   \n",
       "490                         0.517723       208.165859   \n",
       "491                         0.517723       208.165859   \n",
       "492                         0.517723       208.165859   \n",
       "\n",
       "     attChiSquaredNormalized  attClassifierLogisticNormalized  \\\n",
       "0                   1.000000                         0.988836   \n",
       "1                   0.994371                         1.000000   \n",
       "2                   0.470954                         0.657097   \n",
       "3                   0.263171                         0.357257   \n",
       "4                   1.000000                         1.000000   \n",
       "..                       ...                              ...   \n",
       "488                 0.222956                         0.350015   \n",
       "489                 0.178550                         0.249975   \n",
       "490                 0.091768                         0.000000   \n",
       "491                 0.058555                         0.000000   \n",
       "492                 0.023116                         0.000000   \n",
       "\n",
       "     attCorrelationNormalized  attReliefFNormalized  \\\n",
       "0                    1.000000              0.954787   \n",
       "1                    0.962602              1.000000   \n",
       "2                    0.777236              0.372340   \n",
       "3                    0.645528              0.324468   \n",
       "4                    0.878689              0.956530   \n",
       "..                        ...                   ...   \n",
       "488                  0.463506              0.363265   \n",
       "489                  0.555631              0.366118   \n",
       "490                  0.297375              0.046668   \n",
       "491                  0.154953              0.105274   \n",
       "492                  0.170703             -0.003189   \n",
       "\n",
       "     attSymmetricalUncertNormalized  dsLOGnInstances  dsLnNumClasses  \\\n",
       "0                          0.925373         2.176091        1.098612   \n",
       "1                          1.000000         2.176091        1.098612   \n",
       "2                          0.469575         2.176091        1.098612   \n",
       "3                          0.275545         2.176091        1.098612   \n",
       "4                          1.000000         1.755875        0.693147   \n",
       "..                              ...              ...             ...   \n",
       "488                        0.383380         2.004321        1.945910   \n",
       "489                        0.299295         2.004321        1.945910   \n",
       "490                        0.156368         2.004321        1.945910   \n",
       "491                        0.090641         2.004321        1.945910   \n",
       "492                        0.056384         2.004321        1.945910   \n",
       "\n",
       "                 attributeName  datasetName  \n",
       "0                  petallength         iris  \n",
       "1                   petalwidth         iris  \n",
       "2                  sepallength         iris  \n",
       "3                   sepalwidth         iris  \n",
       "4    wage-increase-second-year  labor_part1  \n",
       "..                         ...          ...  \n",
       "488                    aquatic          zoo  \n",
       "489                    catsize          zoo  \n",
       "490                   venomous          zoo  \n",
       "491                   predator          zoo  \n",
       "492                   domestic          zoo  \n",
       "\n",
       "[493 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4806a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dsMatrixCorrelSD</th>\n",
       "      <th>dsEigenvaluePropIntercept</th>\n",
       "      <th>dsEigenvalueCumulativeIntercept</th>\n",
       "      <th>dsChiSquaredMax</th>\n",
       "      <th>attChiSquaredNormalized</th>\n",
       "      <th>attClassifierLogisticNormalized</th>\n",
       "      <th>attCorrelationNormalized</th>\n",
       "      <th>attReliefFNormalized</th>\n",
       "      <th>attSymmetricalUncertNormalized</th>\n",
       "      <th>dsLOGnInstances</th>\n",
       "      <th>dsLnNumClasses</th>\n",
       "      <th>attributeName</th>\n",
       "      <th>datasetName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666645</td>\n",
       "      <td>0.493463</td>\n",
       "      <td>0.719181</td>\n",
       "      <td>268.419048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954787</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>2.176091</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>petallength</td>\n",
       "      <td>iris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666645</td>\n",
       "      <td>0.493463</td>\n",
       "      <td>0.719181</td>\n",
       "      <td>268.419048</td>\n",
       "      <td>0.994371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.176091</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>petalwidth</td>\n",
       "      <td>iris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666645</td>\n",
       "      <td>0.493463</td>\n",
       "      <td>0.719181</td>\n",
       "      <td>268.419048</td>\n",
       "      <td>0.470954</td>\n",
       "      <td>0.657097</td>\n",
       "      <td>0.777236</td>\n",
       "      <td>0.372340</td>\n",
       "      <td>0.469575</td>\n",
       "      <td>2.176091</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>sepallength</td>\n",
       "      <td>iris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666645</td>\n",
       "      <td>0.493463</td>\n",
       "      <td>0.719181</td>\n",
       "      <td>268.419048</td>\n",
       "      <td>0.263171</td>\n",
       "      <td>0.357257</td>\n",
       "      <td>0.645528</td>\n",
       "      <td>0.324468</td>\n",
       "      <td>0.275545</td>\n",
       "      <td>2.176091</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>sepalwidth</td>\n",
       "      <td>iris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.406496</td>\n",
       "      <td>0.216496</td>\n",
       "      <td>0.398940</td>\n",
       "      <td>15.064286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878689</td>\n",
       "      <td>0.956530</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.755875</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>wage-increase-second-year</td>\n",
       "      <td>labor_part1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.381562</td>\n",
       "      <td>0.156774</td>\n",
       "      <td>0.517723</td>\n",
       "      <td>208.165859</td>\n",
       "      <td>0.222956</td>\n",
       "      <td>0.350015</td>\n",
       "      <td>0.463506</td>\n",
       "      <td>0.363265</td>\n",
       "      <td>0.383380</td>\n",
       "      <td>2.004321</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>aquatic</td>\n",
       "      <td>zoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.381562</td>\n",
       "      <td>0.156774</td>\n",
       "      <td>0.517723</td>\n",
       "      <td>208.165859</td>\n",
       "      <td>0.178550</td>\n",
       "      <td>0.249975</td>\n",
       "      <td>0.555631</td>\n",
       "      <td>0.366118</td>\n",
       "      <td>0.299295</td>\n",
       "      <td>2.004321</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>catsize</td>\n",
       "      <td>zoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.381562</td>\n",
       "      <td>0.156774</td>\n",
       "      <td>0.517723</td>\n",
       "      <td>208.165859</td>\n",
       "      <td>0.091768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297375</td>\n",
       "      <td>0.046668</td>\n",
       "      <td>0.156368</td>\n",
       "      <td>2.004321</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>venomous</td>\n",
       "      <td>zoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.381562</td>\n",
       "      <td>0.156774</td>\n",
       "      <td>0.517723</td>\n",
       "      <td>208.165859</td>\n",
       "      <td>0.058555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154953</td>\n",
       "      <td>0.105274</td>\n",
       "      <td>0.090641</td>\n",
       "      <td>2.004321</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>predator</td>\n",
       "      <td>zoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.381562</td>\n",
       "      <td>0.156774</td>\n",
       "      <td>0.517723</td>\n",
       "      <td>208.165859</td>\n",
       "      <td>0.023116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170703</td>\n",
       "      <td>-0.003189</td>\n",
       "      <td>0.056384</td>\n",
       "      <td>2.004321</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>domestic</td>\n",
       "      <td>zoo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dsMatrixCorrelSD  dsEigenvaluePropIntercept  \\\n",
       "0            0.666645                   0.493463   \n",
       "1            0.666645                   0.493463   \n",
       "2            0.666645                   0.493463   \n",
       "3            0.666645                   0.493463   \n",
       "4            0.406496                   0.216496   \n",
       "..                ...                        ...   \n",
       "488          0.381562                   0.156774   \n",
       "489          0.381562                   0.156774   \n",
       "490          0.381562                   0.156774   \n",
       "491          0.381562                   0.156774   \n",
       "492          0.381562                   0.156774   \n",
       "\n",
       "     dsEigenvalueCumulativeIntercept  dsChiSquaredMax  \\\n",
       "0                           0.719181       268.419048   \n",
       "1                           0.719181       268.419048   \n",
       "2                           0.719181       268.419048   \n",
       "3                           0.719181       268.419048   \n",
       "4                           0.398940        15.064286   \n",
       "..                               ...              ...   \n",
       "488                         0.517723       208.165859   \n",
       "489                         0.517723       208.165859   \n",
       "490                         0.517723       208.165859   \n",
       "491                         0.517723       208.165859   \n",
       "492                         0.517723       208.165859   \n",
       "\n",
       "     attChiSquaredNormalized  attClassifierLogisticNormalized  \\\n",
       "0                   1.000000                         0.988836   \n",
       "1                   0.994371                         1.000000   \n",
       "2                   0.470954                         0.657097   \n",
       "3                   0.263171                         0.357257   \n",
       "4                   1.000000                         1.000000   \n",
       "..                       ...                              ...   \n",
       "488                 0.222956                         0.350015   \n",
       "489                 0.178550                         0.249975   \n",
       "490                 0.091768                         0.000000   \n",
       "491                 0.058555                         0.000000   \n",
       "492                 0.023116                         0.000000   \n",
       "\n",
       "     attCorrelationNormalized  attReliefFNormalized  \\\n",
       "0                    1.000000              0.954787   \n",
       "1                    0.962602              1.000000   \n",
       "2                    0.777236              0.372340   \n",
       "3                    0.645528              0.324468   \n",
       "4                    0.878689              0.956530   \n",
       "..                        ...                   ...   \n",
       "488                  0.463506              0.363265   \n",
       "489                  0.555631              0.366118   \n",
       "490                  0.297375              0.046668   \n",
       "491                  0.154953              0.105274   \n",
       "492                  0.170703             -0.003189   \n",
       "\n",
       "     attSymmetricalUncertNormalized  dsLOGnInstances  dsLnNumClasses  \\\n",
       "0                          0.925373         2.176091        1.098612   \n",
       "1                          1.000000         2.176091        1.098612   \n",
       "2                          0.469575         2.176091        1.098612   \n",
       "3                          0.275545         2.176091        1.098612   \n",
       "4                          1.000000         1.755875        0.693147   \n",
       "..                              ...              ...             ...   \n",
       "488                        0.383380         2.004321        1.945910   \n",
       "489                        0.299295         2.004321        1.945910   \n",
       "490                        0.156368         2.004321        1.945910   \n",
       "491                        0.090641         2.004321        1.945910   \n",
       "492                        0.056384         2.004321        1.945910   \n",
       "\n",
       "                 attributeName  datasetName  \n",
       "0                  petallength         iris  \n",
       "1                   petalwidth         iris  \n",
       "2                  sepallength         iris  \n",
       "3                   sepalwidth         iris  \n",
       "4    wage-increase-second-year  labor_part1  \n",
       "..                         ...          ...  \n",
       "488                    aquatic          zoo  \n",
       "489                    catsize          zoo  \n",
       "490                   venomous          zoo  \n",
       "491                   predator          zoo  \n",
       "492                   domestic          zoo  \n",
       "\n",
       "[493 rows x 13 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edae967e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseClassifier</th>\n",
       "      <th>datasetName</th>\n",
       "      <th>attributeName</th>\n",
       "      <th>dsMatrixCorrelSD</th>\n",
       "      <th>dsEigenvaluePropIntercept</th>\n",
       "      <th>dsEigenvalueCumulativeIntercept</th>\n",
       "      <th>dsChiSquaredMax</th>\n",
       "      <th>attChiSquaredNormalized</th>\n",
       "      <th>attClassifierLogisticNormalized</th>\n",
       "      <th>attCorrelationNormalized</th>\n",
       "      <th>attReliefFNormalized</th>\n",
       "      <th>attSymmetricalUncertNormalized</th>\n",
       "      <th>dsLOGnInstances</th>\n",
       "      <th>dsLnNumClasses</th>\n",
       "      <th>wrapperRelevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>iris</td>\n",
       "      <td>petallength</td>\n",
       "      <td>0.666645</td>\n",
       "      <td>0.493463</td>\n",
       "      <td>0.719181</td>\n",
       "      <td>268.419048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954787</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>2.176091</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>iris</td>\n",
       "      <td>petalwidth</td>\n",
       "      <td>0.666645</td>\n",
       "      <td>0.493463</td>\n",
       "      <td>0.719181</td>\n",
       "      <td>268.419048</td>\n",
       "      <td>0.994371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.176091</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>iris</td>\n",
       "      <td>sepallength</td>\n",
       "      <td>0.666645</td>\n",
       "      <td>0.493463</td>\n",
       "      <td>0.719181</td>\n",
       "      <td>268.419048</td>\n",
       "      <td>0.470954</td>\n",
       "      <td>0.657097</td>\n",
       "      <td>0.777236</td>\n",
       "      <td>0.372340</td>\n",
       "      <td>0.469575</td>\n",
       "      <td>2.176091</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>iris</td>\n",
       "      <td>sepalwidth</td>\n",
       "      <td>0.666645</td>\n",
       "      <td>0.493463</td>\n",
       "      <td>0.719181</td>\n",
       "      <td>268.419048</td>\n",
       "      <td>0.263171</td>\n",
       "      <td>0.357257</td>\n",
       "      <td>0.645528</td>\n",
       "      <td>0.324468</td>\n",
       "      <td>0.275545</td>\n",
       "      <td>2.176091</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>labor_part1</td>\n",
       "      <td>wage-increase-second-year</td>\n",
       "      <td>0.406496</td>\n",
       "      <td>0.216496</td>\n",
       "      <td>0.398940</td>\n",
       "      <td>15.064286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878689</td>\n",
       "      <td>0.956530</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.755875</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>zoo</td>\n",
       "      <td>aquatic</td>\n",
       "      <td>0.381562</td>\n",
       "      <td>0.156774</td>\n",
       "      <td>0.517723</td>\n",
       "      <td>208.165859</td>\n",
       "      <td>0.222956</td>\n",
       "      <td>0.350015</td>\n",
       "      <td>0.463506</td>\n",
       "      <td>0.363265</td>\n",
       "      <td>0.383380</td>\n",
       "      <td>2.004321</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>zoo</td>\n",
       "      <td>catsize</td>\n",
       "      <td>0.381562</td>\n",
       "      <td>0.156774</td>\n",
       "      <td>0.517723</td>\n",
       "      <td>208.165859</td>\n",
       "      <td>0.178550</td>\n",
       "      <td>0.249975</td>\n",
       "      <td>0.555631</td>\n",
       "      <td>0.366118</td>\n",
       "      <td>0.299295</td>\n",
       "      <td>2.004321</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>zoo</td>\n",
       "      <td>venomous</td>\n",
       "      <td>0.381562</td>\n",
       "      <td>0.156774</td>\n",
       "      <td>0.517723</td>\n",
       "      <td>208.165859</td>\n",
       "      <td>0.091768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297375</td>\n",
       "      <td>0.046668</td>\n",
       "      <td>0.156368</td>\n",
       "      <td>2.004321</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>zoo</td>\n",
       "      <td>predator</td>\n",
       "      <td>0.381562</td>\n",
       "      <td>0.156774</td>\n",
       "      <td>0.517723</td>\n",
       "      <td>208.165859</td>\n",
       "      <td>0.058555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154953</td>\n",
       "      <td>0.105274</td>\n",
       "      <td>0.090641</td>\n",
       "      <td>2.004321</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>simpleLogisticRegression</td>\n",
       "      <td>zoo</td>\n",
       "      <td>domestic</td>\n",
       "      <td>0.381562</td>\n",
       "      <td>0.156774</td>\n",
       "      <td>0.517723</td>\n",
       "      <td>208.165859</td>\n",
       "      <td>0.023116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170703</td>\n",
       "      <td>-0.003189</td>\n",
       "      <td>0.056384</td>\n",
       "      <td>2.004321</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               baseClassifier  datasetName              attributeName  \\\n",
       "0    simpleLogisticRegression         iris                petallength   \n",
       "1    simpleLogisticRegression         iris                 petalwidth   \n",
       "2    simpleLogisticRegression         iris                sepallength   \n",
       "3    simpleLogisticRegression         iris                 sepalwidth   \n",
       "4    simpleLogisticRegression  labor_part1  wage-increase-second-year   \n",
       "..                        ...          ...                        ...   \n",
       "488  simpleLogisticRegression          zoo                    aquatic   \n",
       "489  simpleLogisticRegression          zoo                    catsize   \n",
       "490  simpleLogisticRegression          zoo                   venomous   \n",
       "491  simpleLogisticRegression          zoo                   predator   \n",
       "492  simpleLogisticRegression          zoo                   domestic   \n",
       "\n",
       "     dsMatrixCorrelSD  dsEigenvaluePropIntercept  \\\n",
       "0            0.666645                   0.493463   \n",
       "1            0.666645                   0.493463   \n",
       "2            0.666645                   0.493463   \n",
       "3            0.666645                   0.493463   \n",
       "4            0.406496                   0.216496   \n",
       "..                ...                        ...   \n",
       "488          0.381562                   0.156774   \n",
       "489          0.381562                   0.156774   \n",
       "490          0.381562                   0.156774   \n",
       "491          0.381562                   0.156774   \n",
       "492          0.381562                   0.156774   \n",
       "\n",
       "     dsEigenvalueCumulativeIntercept  dsChiSquaredMax  \\\n",
       "0                           0.719181       268.419048   \n",
       "1                           0.719181       268.419048   \n",
       "2                           0.719181       268.419048   \n",
       "3                           0.719181       268.419048   \n",
       "4                           0.398940        15.064286   \n",
       "..                               ...              ...   \n",
       "488                         0.517723       208.165859   \n",
       "489                         0.517723       208.165859   \n",
       "490                         0.517723       208.165859   \n",
       "491                         0.517723       208.165859   \n",
       "492                         0.517723       208.165859   \n",
       "\n",
       "     attChiSquaredNormalized  attClassifierLogisticNormalized  \\\n",
       "0                   1.000000                         0.988836   \n",
       "1                   0.994371                         1.000000   \n",
       "2                   0.470954                         0.657097   \n",
       "3                   0.263171                         0.357257   \n",
       "4                   1.000000                         1.000000   \n",
       "..                       ...                              ...   \n",
       "488                 0.222956                         0.350015   \n",
       "489                 0.178550                         0.249975   \n",
       "490                 0.091768                         0.000000   \n",
       "491                 0.058555                         0.000000   \n",
       "492                 0.023116                         0.000000   \n",
       "\n",
       "     attCorrelationNormalized  attReliefFNormalized  \\\n",
       "0                    1.000000              0.954787   \n",
       "1                    0.962602              1.000000   \n",
       "2                    0.777236              0.372340   \n",
       "3                    0.645528              0.324468   \n",
       "4                    0.878689              0.956530   \n",
       "..                        ...                   ...   \n",
       "488                  0.463506              0.363265   \n",
       "489                  0.555631              0.366118   \n",
       "490                  0.297375              0.046668   \n",
       "491                  0.154953              0.105274   \n",
       "492                  0.170703             -0.003189   \n",
       "\n",
       "     attSymmetricalUncertNormalized  dsLOGnInstances  dsLnNumClasses  \\\n",
       "0                          0.925373         2.176091        1.098612   \n",
       "1                          1.000000         2.176091        1.098612   \n",
       "2                          0.469575         2.176091        1.098612   \n",
       "3                          0.275545         2.176091        1.098612   \n",
       "4                          1.000000         1.755875        0.693147   \n",
       "..                              ...              ...             ...   \n",
       "488                        0.383380         2.004321        1.945910   \n",
       "489                        0.299295         2.004321        1.945910   \n",
       "490                        0.156368         2.004321        1.945910   \n",
       "491                        0.090641         2.004321        1.945910   \n",
       "492                        0.056384         2.004321        1.945910   \n",
       "\n",
       "    wrapperRelevance  \n",
       "0                 no  \n",
       "1                yes  \n",
       "2                 no  \n",
       "3                 no  \n",
       "4                yes  \n",
       "..               ...  \n",
       "488              yes  \n",
       "489               no  \n",
       "490               no  \n",
       "491               no  \n",
       "492               no  \n",
       "\n",
       "[493 rows x 15 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging dataframes\n",
    "merged_df = pd.merge(data_set,descriptors_df, on=['datasetName', 'attributeName'],how='inner')\n",
    "\n",
    "# moving wrapper_relevance_column to last position\n",
    "wrapper_relevance_column = merged_df.pop('wrapperRelevance')\n",
    "merged_df = merged_df.assign(wrapperRelevance=wrapper_relevance_column)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9a68413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to a text file\n",
    "merged_df.to_csv('merged.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e53911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data\\\\processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f4a86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save DataFrame to pickle file\n",
    "merged_df.to_pickle(\"data_set.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b11a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in groups.unique():\n",
    "    exec('dataset_{KEY}.to_pickle(\"dataset_{KEY}.pkl\")'.format(KEY = i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d05c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(os.path.dirname(os.getcwd())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06c96cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save DataFrame to pickle file\n",
    "os.chdir('reports')\n",
    "table1.to_pickle(\"table1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1952f747",
   "metadata": {},
   "source": [
    "### Descriptors Diabets Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51a6c1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "cdc_diabetes_health_indicators = fetch_ucirepo(id=891) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = cdc_diabetes_health_indicators.data.features \n",
    "y = cdc_diabetes_health_indicators.data.targets \n",
    "  \n",
    "# # metadata \n",
    "# print(cdc_diabetes_health_indicators.metadata) \n",
    "  \n",
    "# # variable information \n",
    "# print(cdc_diabetes_health_indicators.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06e2835b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>Diabetes_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253675</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253676</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253677</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253678</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253679</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253680 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        HighBP  HighChol  CholCheck  BMI  Smoker  Stroke  \\\n",
       "0            1         1          1   40       1       0   \n",
       "1            0         0          0   25       1       0   \n",
       "2            1         1          1   28       0       0   \n",
       "3            1         0          1   27       0       0   \n",
       "4            1         1          1   24       0       0   \n",
       "...        ...       ...        ...  ...     ...     ...   \n",
       "253675       1         1          1   45       0       0   \n",
       "253676       1         1          1   18       0       0   \n",
       "253677       0         0          1   28       0       0   \n",
       "253678       1         0          1   23       0       0   \n",
       "253679       1         1          1   25       0       0   \n",
       "\n",
       "        HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  ...  NoDocbcCost  \\\n",
       "0                          0             0       0        1  ...            0   \n",
       "1                          0             1       0        0  ...            1   \n",
       "2                          0             0       1        0  ...            1   \n",
       "3                          0             1       1        1  ...            0   \n",
       "4                          0             1       1        1  ...            0   \n",
       "...                      ...           ...     ...      ...  ...          ...   \n",
       "253675                     0             0       1        1  ...            0   \n",
       "253676                     0             0       0        0  ...            0   \n",
       "253677                     0             1       1        0  ...            0   \n",
       "253678                     0             0       1        1  ...            0   \n",
       "253679                     1             1       1        0  ...            0   \n",
       "\n",
       "        GenHlth  MentHlth  PhysHlth  DiffWalk  Sex  Age  Education  Income  \\\n",
       "0             5        18        15         1    0    9          4       3   \n",
       "1             3         0         0         0    0    7          6       1   \n",
       "2             5        30        30         1    0    9          4       8   \n",
       "3             2         0         0         0    0   11          3       6   \n",
       "4             2         3         0         0    0   11          5       4   \n",
       "...         ...       ...       ...       ...  ...  ...        ...     ...   \n",
       "253675        3         0         5         0    1    5          6       7   \n",
       "253676        4         0         0         1    0   11          2       4   \n",
       "253677        1         0         0         0    0    2          5       2   \n",
       "253678        3         0         0         0    1    7          5       1   \n",
       "253679        2         0         0         0    0    9          6       2   \n",
       "\n",
       "        Diabetes_binary  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "253675                0  \n",
       "253676                1  \n",
       "253677                0  \n",
       "253678                0  \n",
       "253679                1  \n",
       "\n",
       "[253680 rows x 22 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_data_set = pd.DataFrame(None)\n",
    "# big_data_set = pd.concat([X.iloc[0:2000,:],y.iloc[0:2000,:]], axis=1)\n",
    "big_data_set = pd.concat([X,y], axis=1)\n",
    "big_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b44e308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_data_set = pd.read_csv(\"data\\external\\bigdataset.csv\",sep=';',decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a86a1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining categorical columns\n",
    "big_data_set['HighBP'] = big_data_set['HighBP'].astype('O')\n",
    "big_data_set['HighChol'] = big_data_set['HighChol'].astype('O')\n",
    "big_data_set['CholCheck'] = big_data_set['CholCheck'].astype('O')\n",
    "big_data_set['Smoker'] = big_data_set['Smoker'].astype('O')\n",
    "big_data_set['Stroke'] = big_data_set['Stroke'].astype('O')\n",
    "big_data_set['HeartDiseaseorAttack'] = big_data_set['HeartDiseaseorAttack'].astype('O')\n",
    "big_data_set['PhysActivity'] = big_data_set['PhysActivity'].astype('O')\n",
    "big_data_set['Fruits'] = big_data_set['Fruits'].astype('O')\n",
    "big_data_set['Veggies'] = big_data_set['Veggies'].astype('O')\n",
    "big_data_set['HvyAlcoholConsump'] = big_data_set['HvyAlcoholConsump'].astype('O')\n",
    "big_data_set['AnyHealthcare'] = big_data_set['AnyHealthcare'].astype('O')\n",
    "big_data_set['NoDocbcCost'] = big_data_set['NoDocbcCost'].astype('O')\n",
    "big_data_set['GenHlth'] = big_data_set['GenHlth'].astype('O')\n",
    "big_data_set['DiffWalk'] = big_data_set['DiffWalk'].astype('O')\n",
    "big_data_set['Sex'] = big_data_set['Sex'].astype('O')\n",
    "big_data_set['Age'] = big_data_set['Age'].astype('O')\n",
    "big_data_set['Education'] = big_data_set['Education'].astype('O')\n",
    "big_data_set['Income'] = big_data_set['Income'].astype('O')\n",
    "big_data_set['Diabetes_binary'] = big_data_set['Diabetes_binary'].astype('O')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9399277",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('data\\\\processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf32b9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file big_data_set.arff already exists.\n"
     ]
    }
   ],
   "source": [
    "# creating arff file\n",
    "if not os.path.isfile('big_data_set.arff'):\n",
    "# File does not exist, create the ARFF file\n",
    "    start_time = time.time()\n",
    "    pandas2arff(big_data_set,  \"big_data_set.arff\",\"big_data_set\")\n",
    "    end_time = time.time()\n",
    "    time_spent = end_time - start_time\n",
    "    print(\"Time spent: \", time_spent)\n",
    "else:\n",
    "    print('The file big_data_set.arff already exists.')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "183990be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a dataset\n",
    "data = converters.load_any_file(\"big_data_set.arff\")\n",
    "data.class_is_last()\n",
    "\n",
    "data2 = converters.load_any_file(\"big_data_set.arff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4943423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent:  28248.427024126053\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "descriptors_df_bigdata = descriptors(data,data2)\n",
    "\n",
    "end_time = time.time()\n",
    "time_spent = end_time - start_time\n",
    "print(\"Time spent: \", time_spent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c71a840a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dsMatrixCorrelSD</th>\n",
       "      <th>dsEigenvaluePropIntercept</th>\n",
       "      <th>dsEigenvalueCumulativeIntercept</th>\n",
       "      <th>dsChiSquaredMax</th>\n",
       "      <th>attChiSquaredNormalized</th>\n",
       "      <th>attClassifierLogisticNormalized</th>\n",
       "      <th>attCorrelationNormalized</th>\n",
       "      <th>attReliefFNormalized</th>\n",
       "      <th>attSymmetricalUncertNormalized</th>\n",
       "      <th>dsLOGnInstances</th>\n",
       "      <th>dsLnNumClasses</th>\n",
       "      <th>attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.494489</td>\n",
       "      <td>0.469193</td>\n",
       "      <td>0.740058</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>GenHlth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.772788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.155079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>HighBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.642423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.824021</td>\n",
       "      <td>0.046219</td>\n",
       "      <td>0.272842</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>BMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.532118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.829723</td>\n",
       "      <td>0.013901</td>\n",
       "      <td>0.722517</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>DiffWalk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.447695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761307</td>\n",
       "      <td>0.124741</td>\n",
       "      <td>0.569867</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>HighChol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.386969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.172938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.220080</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.352128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.651083</td>\n",
       "      <td>0.031842</td>\n",
       "      <td>0.263792</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>PhysHlth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.350796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.673888</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.542532</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>HeartDiseaseorAttack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.308153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258837</td>\n",
       "      <td>0.327522</td>\n",
       "      <td>0.187762</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.177187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254276</td>\n",
       "      <td>0.213261</td>\n",
       "      <td>0.141861</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.155764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.448879</td>\n",
       "      <td>0.078262</td>\n",
       "      <td>0.209106</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>PhysActivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.124976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.402128</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.239188</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.062185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.263398</td>\n",
       "      <td>0.039743</td>\n",
       "      <td>0.050961</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>MentHlth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.046811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.246294</td>\n",
       "      <td>0.093672</td>\n",
       "      <td>0.164478</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>CholCheck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.041245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.231091</td>\n",
       "      <td>0.112561</td>\n",
       "      <td>0.052265</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.036335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.217028</td>\n",
       "      <td>0.107801</td>\n",
       "      <td>0.099857</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>HvyAlcoholConsump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.035737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.215127</td>\n",
       "      <td>0.080428</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Veggies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.018561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.155074</td>\n",
       "      <td>0.110692</td>\n",
       "      <td>0.023998</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.011028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119346</td>\n",
       "      <td>0.058012</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>NoDocbcCost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.011026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119346</td>\n",
       "      <td>0.136566</td>\n",
       "      <td>0.014017</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.163404</td>\n",
       "      <td>0.03588</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>22728.069055</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061954</td>\n",
       "      <td>0.056249</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>5.404286</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>AnyHealthcare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dsMatrixCorrelSD  dsEigenvaluePropIntercept  \\\n",
       "0           0.163404                    0.03588   \n",
       "1           0.163404                    0.03588   \n",
       "2           0.163404                    0.03588   \n",
       "3           0.163404                    0.03588   \n",
       "4           0.163404                    0.03588   \n",
       "5           0.163404                    0.03588   \n",
       "6           0.163404                    0.03588   \n",
       "7           0.163404                    0.03588   \n",
       "8           0.163404                    0.03588   \n",
       "9           0.163404                    0.03588   \n",
       "10          0.163404                    0.03588   \n",
       "11          0.163404                    0.03588   \n",
       "12          0.163404                    0.03588   \n",
       "13          0.163404                    0.03588   \n",
       "14          0.163404                    0.03588   \n",
       "15          0.163404                    0.03588   \n",
       "16          0.163404                    0.03588   \n",
       "17          0.163404                    0.03588   \n",
       "18          0.163404                    0.03588   \n",
       "19          0.163404                    0.03588   \n",
       "20          0.163404                    0.03588   \n",
       "\n",
       "    dsEigenvalueCumulativeIntercept  dsChiSquaredMax  attChiSquaredNormalized  \\\n",
       "0                          0.143081     22728.069055                 1.000000   \n",
       "1                          0.143081     22728.069055                 0.772788   \n",
       "2                          0.143081     22728.069055                 0.642423   \n",
       "3                          0.143081     22728.069055                 0.532118   \n",
       "4                          0.143081     22728.069055                 0.447695   \n",
       "5                          0.143081     22728.069055                 0.386969   \n",
       "6                          0.143081     22728.069055                 0.352128   \n",
       "7                          0.143081     22728.069055                 0.350796   \n",
       "8                          0.143081     22728.069055                 0.308153   \n",
       "9                          0.143081     22728.069055                 0.177187   \n",
       "10                         0.143081     22728.069055                 0.155764   \n",
       "11                         0.143081     22728.069055                 0.124976   \n",
       "12                         0.143081     22728.069055                 0.062185   \n",
       "13                         0.143081     22728.069055                 0.046811   \n",
       "14                         0.143081     22728.069055                 0.041245   \n",
       "15                         0.143081     22728.069055                 0.036335   \n",
       "16                         0.143081     22728.069055                 0.035737   \n",
       "17                         0.143081     22728.069055                 0.018561   \n",
       "18                         0.143081     22728.069055                 0.011028   \n",
       "19                         0.143081     22728.069055                 0.011026   \n",
       "20                         0.143081     22728.069055                 0.002949   \n",
       "\n",
       "    attClassifierLogisticNormalized  attCorrelationNormalized  \\\n",
       "0                               NaN                  0.494489   \n",
       "1                               NaN                  1.000000   \n",
       "2                               NaN                  0.824021   \n",
       "3                               NaN                  0.829723   \n",
       "4                               NaN                  0.761307   \n",
       "5                               NaN                  0.172938   \n",
       "6                               NaN                  0.651083   \n",
       "7                               NaN                  0.673888   \n",
       "8                               NaN                  0.258837   \n",
       "9                               NaN                  0.254276   \n",
       "10                              NaN                  0.448879   \n",
       "11                              NaN                  0.402128   \n",
       "12                              NaN                  0.263398   \n",
       "13                              NaN                  0.246294   \n",
       "14                              NaN                  0.231091   \n",
       "15                              NaN                  0.217028   \n",
       "16                              NaN                  0.215127   \n",
       "17                              NaN                  0.155074   \n",
       "18                              NaN                  0.119346   \n",
       "19                              NaN                  0.119346   \n",
       "20                              NaN                  0.061954   \n",
       "\n",
       "    attReliefFNormalized  attSymmetricalUncertNormalized  dsLOGnInstances  \\\n",
       "0               0.469193                        0.740058         5.404286   \n",
       "1               0.155079                        1.000000         5.404286   \n",
       "2               0.046219                        0.272842         5.404286   \n",
       "3               0.013901                        0.722517         5.404286   \n",
       "4               0.124741                        0.569867         5.404286   \n",
       "5               1.000000                        0.220080         5.404286   \n",
       "6               0.031842                        0.263792         5.404286   \n",
       "7               0.007514                        0.542532         5.404286   \n",
       "8               0.327522                        0.187762         5.404286   \n",
       "9               0.213261                        0.141861         5.404286   \n",
       "10              0.078262                        0.209106         5.404286   \n",
       "11              0.004226                        0.239188         5.404286   \n",
       "12              0.039743                        0.050961         5.404286   \n",
       "13              0.093672                        0.164478         5.404286   \n",
       "14              0.112561                        0.052265         5.404286   \n",
       "15              0.107801                        0.099857         5.404286   \n",
       "16              0.080428                        0.052948         5.404286   \n",
       "17              0.110692                        0.023998         5.404286   \n",
       "18              0.058012                        0.020862         5.404286   \n",
       "19              0.136566                        0.014017         5.404286   \n",
       "20              0.056249                        0.007203         5.404286   \n",
       "\n",
       "    dsLnNumClasses             attribute  \n",
       "0         0.693147               GenHlth  \n",
       "1         0.693147                HighBP  \n",
       "2         0.693147                   BMI  \n",
       "3         0.693147              DiffWalk  \n",
       "4         0.693147              HighChol  \n",
       "5         0.693147                   Age  \n",
       "6         0.693147              PhysHlth  \n",
       "7         0.693147  HeartDiseaseorAttack  \n",
       "8         0.693147                Income  \n",
       "9         0.693147             Education  \n",
       "10        0.693147          PhysActivity  \n",
       "11        0.693147                Stroke  \n",
       "12        0.693147              MentHlth  \n",
       "13        0.693147             CholCheck  \n",
       "14        0.693147                Smoker  \n",
       "15        0.693147     HvyAlcoholConsump  \n",
       "16        0.693147               Veggies  \n",
       "17        0.693147                Fruits  \n",
       "18        0.693147           NoDocbcCost  \n",
       "19        0.693147                   Sex  \n",
       "20        0.693147         AnyHealthcare  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptors_df_bigdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81b0b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save DataFrame to pickle file\n",
    "descriptors_df_bigdata.to_pickle(\"descriptors_df_bigdata.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e267381c",
   "metadata": {},
   "source": [
    "### Descriptors of Financial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bce0d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('..')\n",
    "os.chdir('data\\\\external')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f783bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a dataset\n",
    "data = converters.load_any_file(\"big_data_set2.arff\")\n",
    "data.class_is_last()\n",
    "\n",
    "data2 = converters.load_any_file(\"big_data_set2.arff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14a1f22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent:  184.0481402873993\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "descriptors_df_bigdata2 = descriptors(data,data2)\n",
    "\n",
    "end_time = time.time()\n",
    "time_spent = end_time - start_time\n",
    "print(\"Time spent: \", time_spent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ae1b277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dsMatrixCorrelSD</th>\n",
       "      <th>dsEigenvaluePropIntercept</th>\n",
       "      <th>dsEigenvalueCumulativeIntercept</th>\n",
       "      <th>dsChiSquaredMax</th>\n",
       "      <th>attChiSquaredNormalized</th>\n",
       "      <th>attClassifierLogisticNormalized</th>\n",
       "      <th>attCorrelationNormalized</th>\n",
       "      <th>attReliefFNormalized</th>\n",
       "      <th>attSymmetricalUncertNormalized</th>\n",
       "      <th>dsLOGnInstances</th>\n",
       "      <th>dsLnNumClasses</th>\n",
       "      <th>attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288967</td>\n",
       "      <td>0.05152</td>\n",
       "      <td>0.649535</td>\n",
       "      <td>1013.224087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.374215</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.771587</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Attr35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.288967</td>\n",
       "      <td>0.05152</td>\n",
       "      <td>0.649535</td>\n",
       "      <td>1013.224087</td>\n",
       "      <td>0.963439</td>\n",
       "      <td>-0.277778</td>\n",
       "      <td>0.637058</td>\n",
       "      <td>0.027382</td>\n",
       "      <td>0.826957</td>\n",
       "      <td>3.771587</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Attr39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.288967</td>\n",
       "      <td>0.05152</td>\n",
       "      <td>0.649535</td>\n",
       "      <td>1013.224087</td>\n",
       "      <td>0.937163</td>\n",
       "      <td>-0.222222</td>\n",
       "      <td>0.354931</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.615657</td>\n",
       "      <td>3.771587</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Attr22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.288967</td>\n",
       "      <td>0.05152</td>\n",
       "      <td>0.649535</td>\n",
       "      <td>1013.224087</td>\n",
       "      <td>0.867532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146202</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.886571</td>\n",
       "      <td>3.771587</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Attr42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.288967</td>\n",
       "      <td>0.05152</td>\n",
       "      <td>0.649535</td>\n",
       "      <td>1013.224087</td>\n",
       "      <td>0.844859</td>\n",
       "      <td>-0.055556</td>\n",
       "      <td>0.046529</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.543031</td>\n",
       "      <td>3.771587</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Attr13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.288967</td>\n",
       "      <td>0.05152</td>\n",
       "      <td>0.649535</td>\n",
       "      <td>1013.224087</td>\n",
       "      <td>0.066328</td>\n",
       "      <td>-0.055556</td>\n",
       "      <td>0.369112</td>\n",
       "      <td>0.039090</td>\n",
       "      <td>0.065130</td>\n",
       "      <td>3.771587</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Attr20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.288967</td>\n",
       "      <td>0.05152</td>\n",
       "      <td>0.649535</td>\n",
       "      <td>1013.224087</td>\n",
       "      <td>0.053758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029232</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.085213</td>\n",
       "      <td>3.771587</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Attr47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.288967</td>\n",
       "      <td>0.05152</td>\n",
       "      <td>0.649535</td>\n",
       "      <td>1013.224087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020472</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.771587</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Attr60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.288967</td>\n",
       "      <td>0.05152</td>\n",
       "      <td>0.649535</td>\n",
       "      <td>1013.224087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.771587</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Attr37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.288967</td>\n",
       "      <td>0.05152</td>\n",
       "      <td>0.649535</td>\n",
       "      <td>1013.224087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028089</td>\n",
       "      <td>0.011936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.771587</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>Attr64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dsMatrixCorrelSD  dsEigenvaluePropIntercept  \\\n",
       "0           0.288967                    0.05152   \n",
       "1           0.288967                    0.05152   \n",
       "2           0.288967                    0.05152   \n",
       "3           0.288967                    0.05152   \n",
       "4           0.288967                    0.05152   \n",
       "..               ...                        ...   \n",
       "59          0.288967                    0.05152   \n",
       "60          0.288967                    0.05152   \n",
       "61          0.288967                    0.05152   \n",
       "62          0.288967                    0.05152   \n",
       "63          0.288967                    0.05152   \n",
       "\n",
       "    dsEigenvalueCumulativeIntercept  dsChiSquaredMax  attChiSquaredNormalized  \\\n",
       "0                          0.649535      1013.224087                 1.000000   \n",
       "1                          0.649535      1013.224087                 0.963439   \n",
       "2                          0.649535      1013.224087                 0.937163   \n",
       "3                          0.649535      1013.224087                 0.867532   \n",
       "4                          0.649535      1013.224087                 0.844859   \n",
       "..                              ...              ...                      ...   \n",
       "59                         0.649535      1013.224087                 0.066328   \n",
       "60                         0.649535      1013.224087                 0.053758   \n",
       "61                         0.649535      1013.224087                 0.000000   \n",
       "62                         0.649535      1013.224087                 0.000000   \n",
       "63                         0.649535      1013.224087                 0.000000   \n",
       "\n",
       "    attClassifierLogisticNormalized  attCorrelationNormalized  \\\n",
       "0                          1.000000                  0.374215   \n",
       "1                         -0.277778                  0.637058   \n",
       "2                         -0.222222                  0.354931   \n",
       "3                          0.000000                  0.146202   \n",
       "4                         -0.055556                  0.046529   \n",
       "..                              ...                       ...   \n",
       "59                        -0.055556                  0.369112   \n",
       "60                         0.000000                  0.029232   \n",
       "61                         0.000000                  0.020472   \n",
       "62                         0.000000                  0.062513   \n",
       "63                         0.000000                  0.028089   \n",
       "\n",
       "    attReliefFNormalized  attSymmetricalUncertNormalized  dsLOGnInstances  \\\n",
       "0               0.003931                        1.000000         3.771587   \n",
       "1               0.027382                        0.826957         3.771587   \n",
       "2               0.003575                        0.615657         3.771587   \n",
       "3               0.006732                        0.886571         3.771587   \n",
       "4               0.000606                        0.543031         3.771587   \n",
       "..                   ...                             ...              ...   \n",
       "59              0.039090                        0.065130         3.771587   \n",
       "60              0.008258                        0.085213         3.771587   \n",
       "61              0.000162                        0.000000         3.771587   \n",
       "62              1.000000                        0.000000         3.771587   \n",
       "63              0.011936                        0.000000         3.771587   \n",
       "\n",
       "    dsLnNumClasses attribute  \n",
       "0         0.693147    Attr35  \n",
       "1         0.693147    Attr39  \n",
       "2         0.693147    Attr22  \n",
       "3         0.693147    Attr42  \n",
       "4         0.693147    Attr13  \n",
       "..             ...       ...  \n",
       "59        0.693147    Attr20  \n",
       "60        0.693147    Attr47  \n",
       "61        0.693147    Attr60  \n",
       "62        0.693147    Attr37  \n",
       "63        0.693147    Attr64  \n",
       "\n",
       "[64 rows x 12 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptors_df_bigdata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62362f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ab00549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save DataFrame to pickle file\n",
    "descriptors_df_bigdata2.to_pickle(\"descriptors_df_bigdata2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db65b015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
